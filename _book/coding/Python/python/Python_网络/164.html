
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>从消费者报告网站抓取产品名称 · CoderFAN 资料库</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 6.0.3">
        <meta name="author" content="Todd Lyu">
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="165.html" />
    
    
    <link rel="prev" href="163.html" />
    
    <!-- MathJax 配置：唯一且完整 -->
<script>
    window.MathJax = {
      tex: {
        inlineMath:  [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        processEscapes: true,
        processEnvironments: true,
        strict: "ignore",
        macros: { "\\E":"\\mathbb{E}", "\\Var":"\\operatorname{Var}" }
      },
    };
    </script>
    
    <!-- 核心脚本（defer不阻塞渲染） -->
    <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
    <!-- 放在 tex-chtml.js 之后 -->
    <script>
    (function () {
      function typeset() {
        if (window.MathJax && MathJax.typesetPromise) {
          MathJax.typesetPromise().catch(console.error);
        }
      }
    
      /* 第一次正文插入 */
      document.addEventListener('DOMContentLoaded', typeset);
    
      /*   关键：等待 gitbook.js 初始化成功   */
      function hookGitBook() {
        if (window.gitbook && gitbook.events) {
          gitbook.events.bind('page.change', typeset);   // 切章排版
        } else {
          /* gitbook.js 还没加载完 → 100 ms 后再试 */
          setTimeout(hookGitBook, 100);
        }
      }
      hookGitBook();   // 启动递归等待
    })();
    </script>
    
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
            
                <nav role="navigation">
                <a href=".." class="btn"><b></b>&#128512;返回上层&#128512;</b></a>
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    Python 网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="124.html">
            
                <a href="124.html">
            
                    
                    简介和基础知识
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.2" data-path="125.html">
            
                <a href="125.html">
            
                    
                    网络编程导论
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.3" data-path="126.html">
            
                <a href="126.html">
            
                    
                    常见网络术语
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.4" data-path="127.html">
            
                <a href="127.html">
            
                    
                    安装 Python 第三方库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.5" data-path="128.html">
            
                <a href="128.html">
            
                    
                    解释和交互式 Python
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.6" data-path="129.html">
            
                <a href="129.html">
            
                    
                    套接字基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.7" data-path="130.html">
            
                <a href="130.html">
            
                    
                    Python 套接字——SOCK_STREAM和SOCK_DGRAM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.8" data-path="131.html">
            
                <a href="131.html">
            
                    
                    使用 TCP 套接字
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.9" data-path="132.html">
            
                <a href="132.html">
            
                    
                    使用 UDP 套接字
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.10" data-path="133.html">
            
                <a href="133.html">
            
                    
                    通过 TCP 套接字处理接收的客户端数据
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.11" data-path="134.html">
            
                <a href="134.html">
            
                    
                    阻塞和非阻塞套接字输入/输出
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.12" data-path="135.html">
            
                <a href="135.html">
            
                    
                    通过 TSL/SSL 保护套接字
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.13" data-path="136.html">
            
                <a href="136.html">
            
                    
                    从网络分析开始
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.14" data-path="137.html">
            
                <a href="137.html">
            
                    
                    使用套接字构建自定义端口扫描器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.15" data-path="138.html">
            
                <a href="138.html">
            
                    
                    在 Python 中使用 Nmap 端口扫描器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.16" data-path="139.html">
            
                <a href="139.html">
            
                    
                    使用命令行输入的 Nmap 端口扫描脚本
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.17" data-path="140.html">
            
                <a href="140.html">
            
                    
                    什么是横幅抓取？
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.18" data-path="141.html">
            
                <a href="141.html">
            
                    
                    Wireshark 网络流量分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.19" data-path="142.html">
            
                <a href="142.html">
            
                    
                    Wireshark 数据包分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.20" data-path="143.html">
            
                <a href="143.html">
            
                    
                    使用dpkt库分析网络流量
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.21" data-path="144.html">
            
                <a href="144.html">
            
                    
                    scapy 简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.22" data-path="145.html">
            
                <a href="145.html">
            
                    
                    实际应用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.23" data-path="146.html">
            
                <a href="146.html">
            
                    
                    是时候干活了
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.24" data-path="147.html">
            
                <a href="147.html">
            
                    
                    从 PDF 文件中提取元数据
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.25" data-path="148.html">
            
                <a href="148.html">
            
                    
                    使用pyGeoIP模块
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.26" data-path="149.html">
            
                <a href="149.html">
            
                    
                    什么是网页抓取？
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.27" data-path="150.html">
            
                <a href="150.html">
            
                    
                    实现网页抓取
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.28" data-path="151.html">
            
                <a href="151.html">
            
                    
                    什么是 API？
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.29" data-path="152.html">
            
                <a href="152.html">
            
                    
                    使用脸书 GraphAPI
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.30" data-path="153.html">
            
                <a href="153.html">
            
                    
                    挖掘自己的脸书账户
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.31" data-path="154.html">
            
                <a href="154.html">
            
                    
                    Python 的mechanize库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.32" data-path="155.html">
            
                <a href="155.html">
            
                    
                    使用mechanize库更改浏览器的用户代理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.33" data-path="156.html">
            
                <a href="156.html">
            
                    
                    Web 爬取
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.34" data-path="157.html">
            
                <a href="157.html">
            
                    
                    入门指南
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.35" data-path="158.html">
            
                <a href="158.html">
            
                    
                    网页抓取简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.36" data-path="159.html">
            
                <a href="159.html">
            
                    
                    requests模块简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.37" data-path="160.html">
            
                <a href="160.html">
            
                    
                    beautifulsoup模块简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.38" data-path="161.html">
            
                <a href="161.html">
            
                    
                    进阶
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.39" data-path="162.html">
            
                <a href="162.html">
            
                    
                    探索 BeautifulSoap 方法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.40" data-path="163.html">
            
                <a href="163.html">
            
                    
                    使用 BeautifulSoap 查找 HTML 标签
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.1.41" data-path="164.html">
            
                <a href="164.html">
            
                    
                    从消费者报告网站抓取产品名称
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.42" data-path="165.html">
            
                <a href="165.html">
            
                    
                    高级
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.43" data-path="166.html">
            
                <a href="166.html">
            
                    
                    网页抓取：将数据写入文件
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.44" data-path="167.html">
            
                <a href="167.html">
            
                    
                    网页抓取：抓取多个网址
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.45" data-path="168.html">
            
                <a href="168.html">
            
                    
                    从 StudyTonight 教程网页中抓取主题名称
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >从消费者报告网站抓取产品名称</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
                                <section class="normal markdown-section">
                                
                                <h1 id="从消费者报告网站抓取产品名称">从消费者报告网站抓取产品名称</h1>
<blockquote>
<p>原文：<a href="https://www.studytonight.com/python/web-scraping/web-scraping-practical-example-1" target="_blank">https://www.studytonight.com/python/web-scraping/web-scraping-practical-example-1</a></p>
</blockquote>
<p><strong>注:</strong>本教程仅用于教育目的，我们要求读者不要使用该代码对网站进行任何形式的伤害。</p>
<p>在本教程中，我们将学习如何从任何网站上抓取数据。我们从中获取数据的网站是<strong>消费者报告</strong>网站。我们将从这个<a href="https://www.consumerreports.org/cro/a-to-z-index/products/index.htm" target="_blank">网址</a>请求数据，然后从中收集<strong>产品名称</strong>列表。</p>
<p>让刮擦开始...</p>
<pre><code class="lang-py"><span class="hljs-comment">## importing bs4, requests and fake_useragent modules</span>
<span class="hljs-keyword">import</span> bs4
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> fake_useragent <span class="hljs-keyword">import</span> UserAgent

<span class="hljs-comment">## initializing the UserAgent object</span>
user_agent = UserAgent()
url = <span class="hljs-string">"https://www.consumerreports.org/cro/a-to-z-index/products/index.htm"</span>

<span class="hljs-comment">## getting the reponse from the page using get method of requests module</span>
page = requests.get(url, headers={<span class="hljs-string">"user-agent"</span>: user_agent.chrome})

<span class="hljs-comment">## storing the content of the page in a variable</span>
html = page.content
</code></pre>
<p>到了这一步，我们已经在变量<code>html</code>中存储了网页的完整源代码。现在让我们创建一个漂亮的输出对象。你甚至可以尝试运行<code>prettify</code>方法。</p>
<pre><code class="lang-py"><span class="hljs-comment">## creating BeautifulSoup object</span>
soup = bs4.BeautifulSoup(html, <span class="hljs-string">"html.parser"</span>)
</code></pre>
<p>我们还创建了一个美丽的组对象，现在呢？我们如何知道从 HTML 代码中找到并提取哪个标签。我们应该在 HTML 代码中搜索它吗？不可能！</p>
<p>还记得在本系列的第一个教程中，当我们<a href="introduction-to-web-scraping">引入术语网页抓取</a>时，我们确实与您分享了一种技术，在这里我们可以使用 <strong>Chrome 浏览器的开发工具</strong>来查找任何网页元素的 HTML 代码。(其他浏览器如火狐等也有自己的开发工具，也可以使用。)</p>
<p>如果您使用的是 Windows，请按 <strong>F12</strong> 键打开开发者工具(在 chrome 浏览器中)，如果您是 Mac 用户，请按<strong>选项+命令+ I</strong> 键。</p>
<p>点击左上角按钮:</p>
<p><img src="img/16aaf4caca2bb7e374cdcd68f3185e22.png" alt="web scraping example"></img></p>
<p>然后将鼠标光标悬停在产品列表条目上以查找它们的 HTML 标记:</p>
<p><img src="img/561e69e874b3ac1e81e1237a5de3e180.png" alt="web scraping example"></img></p>
<p>我们可以看到，<strong>锚点</strong>标签包含产品报告页面的网址和产品名称，并包含在一个带有<code>class</code>属性值<strong>的<code>div</code>标签中。这就是我们开始的地方，我们将获取所有<code>div</code>标签，其<code>class</code>属性值等于</strong>症结-身体-副本<strong>:</strong></p>
<pre><code class="lang-py"><span class="hljs-comment">## div tags with crux-body-copy class</span>
div_class = <span class="hljs-string">"crux-body-copy"</span>

<span class="hljs-comment">## getting all the divs with class 'crux-body-copy'</span>
div_tags = soup.find_all(<span class="hljs-string">"div"</span>, class_=<span class="hljs-string">"div_class"</span>)

<span class="hljs-comment">## we will see all the div tags </span>
<span class="hljs-comment">## enclosing the anchor tags with the required info</span>
<span class="hljs-keyword">for</span> tag <span class="hljs-keyword">in</span> div_tags:
    print(tag)
</code></pre>
<p><a href="https://www.consumerreports.org/cro/air-conditioners.htm" target="_blank">空调</a>.........</p>
<p>由于上述代码的完整输出太长，我们将其存储在<a href="resources/cr-product-list-html.txt">文件</a>中(下载文件查看)。</p>
<p>现在下一步是从附带的<code>div</code>标签中提取产品名称和各个产品网页的链接。</p>
<pre><code class="lang-py"><span class="hljs-comment">## extracting the names and links from the div tags</span>
<span class="hljs-keyword">for</span> tag <span class="hljs-keyword">in</span> div_tags:
    name = tag.a.text.strip()
    link = tag.a[<span class="hljs-string">'href'</span>]

    print(<span class="hljs-string">"{} ---- {}"</span>.format(name, link))
</code></pre>
<p>空调-<a href="https://www.consumerreports.org/cro/air-conditioners.htm" target="_blank">https://www.consumerreports.org/cro/air-conditioners.htm</a> 空气过滤器-<a href="https://www.consumerreports.org/cro/air-filters.htm" target="_blank">https://www.consumerreports.org/cro/air-filters.htm</a> 空气油炸锅-<a href="https://www.consumerreports.org/cro/air-fryers.htm" target="_blank">https://www.consumerreports.org/cro/air-fryers.htm</a> 空气床垫-<a href="https://www.consumerreports.org/cro/air-mattresses.htm" target="_blank">https://www.consumerreports.org/cro/air-mattresses.htm</a>.........</p>
<p>看，多简单。有了这个，我们成功地从一个网站上收集了数据。</p>
<p>以下是完整的代码供您参考:</p>
<pre><code class="lang-py"><span class="hljs-comment">## importing bs4, requests and fake_useragent modules</span>
<span class="hljs-keyword">import</span> bs4
<span class="hljs-keyword">import</span> requests
<span class="hljs-keyword">from</span> fake_useragent <span class="hljs-keyword">import</span> UserAgent

<span class="hljs-comment">## initializing the UserAgent object</span>
user_agent = UserAgent()
url = <span class="hljs-string">"https://www.consumerreports.org/cro/a-to-z-index/products/index.htm"</span>

<span class="hljs-comment">## getting the reponse from the page using get method of requests module</span>
page = requests.get(url, headers={<span class="hljs-string">"user-agent"</span>: user_agent.chrome})

<span class="hljs-comment">## storing the content of the page in a variable</span>
html = page.content

<span class="hljs-comment">## creating BeautifulSoup object</span>
soup = bs4.BeautifulSoup(html, <span class="hljs-string">"html.parser"</span>)

<span class="hljs-comment">## div tags with crux-body-copy class</span>
div_class = <span class="hljs-string">"crux-body-copy"</span>

<span class="hljs-comment">## getting all the divs with class 'crux-body-copy'</span>
div_tags = soup.find_all(<span class="hljs-string">"div"</span>, class_=<span class="hljs-string">"div_class"</span>)

<span class="hljs-comment">## extracting the names and links from the div tags</span>
<span class="hljs-keyword">for</span> tag <span class="hljs-keyword">in</span> div_tags:
    name = tag.a.text.strip()
    link = tag.a[<span class="hljs-string">'href'</span>]

    print(<span class="hljs-string">"{} ---- {}"</span>.format(name, link))
</code></pre>
<p>试着在你的机器上运行这段代码，如果你遇到任何问题，你可以在这里发布你的问题: <a href="studyroom"><strong>StudyTonight Q &amp; A 论坛</strong></a></p>
<hr></hr>
<hr></hr>

                                
                                </section>
                            
                        </div>
                    </div>
                
            </div>

            
                
                <a href="163.html" class="navigation navigation-prev " aria-label="Previous page: 使用 BeautifulSoap 查找 HTML 标签">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="165.html" class="navigation navigation-next " aria-label="Next page: 高级">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"从消费者报告网站抓取产品名称","level":"1.1.41","depth":2,"next":{"title":"高级","level":"1.1.42","depth":2,"path":"165.md","ref":"165.md","articles":[]},"previous":{"title":"使用 BeautifulSoap 查找 HTML 标签","level":"1.1.40","depth":2,"path":"163.md","ref":"163.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-search","-livereload","-lunr","-fontsettings","highlight","expandable-chapters-small","back-to-top-button","github","code","theme-default"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"highlight":{"lang":{"eval_rst":"rst","toc":"text"}},"github":{"url":"https://github.com/KittenCN"},"expandable-chapters-small":{},"back-to-top-button":{},"code":{"copyButtons":true},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"Todd Lyu","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"CoderFAN 资料库","gitbook":"*"},"file":{"path":"164.md","mtime":"2025-05-02T04:00:21.233Z","type":"markdown"},"gitbook":{"version":"6.0.3","time":"2025-05-05T05:23:09.109Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-code/plugin.js"></script>
        
    

    </body>
</html>

