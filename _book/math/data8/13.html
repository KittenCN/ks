
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <title>十三、预测 · HonKit</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="HonKit 6.0.2">
        
        
        
    
    <link rel="stylesheet" href="../../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-splitter/splitter.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../../gitbook/@honkit/honkit-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="14.html" />
    
    
    <link rel="prev" href="12.html" />
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../../">
            
                <a href="../../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <a target="_blank" href="https://www.coderfan.com">
            
                    
                    OJ学习平台
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3" data-path="../../standard/">
            
                <a href="../../standard/">
            
                    
                    开发规范
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../../standard/standard.html">
            
                <a href="../../standard/standard.html">
            
                    
                    书写规范
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../../standard/component.html">
            
                <a href="../../standard/component.html">
            
                    
                    组件规范
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../../standard/eslint.html">
            
                <a href="../../standard/eslint.html">
            
                    
                    Eslint
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../../standard/jsdoc.html">
            
                <a href="../../standard/jsdoc.html">
            
                    
                    Jsdoc
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../../standard/yooha.html">
            
                <a href="../../standard/yooha.html">
            
                    
                    雅虎军规
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../../standard/git.html">
            
                <a href="../../standard/git.html">
            
                    
                    git
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" data-path="../../web/">
            
                <a href="../../web/">
            
                    
                    前端汇总
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../../web/css.html">
            
                <a href="../../web/css.html">
            
                    
                    CSS
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../../web/html.html">
            
                <a href="../../web/html.html">
            
                    
                    Html
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../../web/http.html">
            
                <a href="../../web/http.html">
            
                    
                    Http
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="../../web/javascript.html">
            
                <a href="../../web/javascript.html">
            
                    
                    Javascript
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="../../web/array.html">
            
                <a href="../../web/array.html">
            
                    
                    Array
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="../../web/object.html">
            
                <a href="../../web/object.html">
            
                    
                    Object
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.7" data-path="../../web/module.html">
            
                <a href="../../web/module.html">
            
                    
                    Module
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.8" data-path="../../web/regexp.html">
            
                <a href="../../web/regexp.html">
            
                    
                    Regexp
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.9" data-path="../../web/es6.html">
            
                <a href="../../web/es6.html">
            
                    
                    ES6
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.10" data-path="../../web/design.html">
            
                <a href="../../web/design.html">
            
                    
                    设计模式
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.11" data-path="../../web/fp.html">
            
                <a href="../../web/fp.html">
            
                    
                    函数编程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.12" data-path="../../web/typescript.html">
            
                <a href="../../web/typescript.html">
            
                    
                    Typescript
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.13" data-path="../../web/react.html">
            
                <a href="../../web/react.html">
            
                    
                    React
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.14" data-path="../../web/vue.html">
            
                <a href="../../web/vue.html">
            
                    
                    Vue
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.15" data-path="../../web/webpack.html">
            
                <a href="../../web/webpack.html">
            
                    
                    Webpack
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.16" data-path="../../web/vite.html">
            
                <a href="../../web/vite.html">
            
                    
                    Vite
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.17" data-path="../../web/babel.html">
            
                <a href="../../web/babel.html">
            
                    
                    Babel
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" data-path="../../coding/">
            
                <a href="../../coding/">
            
                    
                    后端汇总
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../../coding/CPP.html">
            
                <a href="../../coding/CPP.html">
            
                    
                    CPP
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1.1" data-path="../../coding/CPP/cpp_base/">
            
                <a href="../../coding/CPP/cpp_base/">
            
                    
                    CPP基础
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../../coding/Java.html">
            
                <a href="../../coding/Java.html">
            
                    
                    Java
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.2.1" data-path="../../coding/Java/java_base/">
            
                <a href="../../coding/Java/java_base/">
            
                    
                    Java基础
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../../coding/Python.html">
            
                <a href="../../coding/Python.html">
            
                    
                    Python
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.1" data-path="../../coding/Python/python_base/">
            
                <a href="../../coding/Python/python_base/">
            
                    
                    Python基础
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.1.1" data-path="../../coding/Python/python_base/ch01.html">
            
                <a href="../../coding/Python/python_base/ch01.html">
            
                    
                    ch01. 初识 Python
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.2" data-path="../../coding/Python/python_base/ch02.html">
            
                <a href="../../coding/Python/python_base/ch02.html">
            
                    
                    ch02. Python 运算符与基本数据类型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.3" data-path="../../coding/Python/python_base/ch03.html">
            
                <a href="../../coding/Python/python_base/ch03.html">
            
                    
                    ch03. 玩转 Python 字符串
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.4" data-path="../../coding/Python/python_base/ch04.html">
            
                <a href="../../coding/Python/python_base/ch04.html">
            
                    
                    ch04. Python 序列结构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.5" data-path="../../coding/Python/python_base/ch05.html">
            
                <a href="../../coding/Python/python_base/ch05.html">
            
                    
                    ch05. Python 的三种格式化输出方法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.6" data-path="../../coding/Python/python_base/ch06.html">
            
                <a href="../../coding/Python/python_base/ch06.html">
            
                    
                    ch06. Python 常用内置函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.7" data-path="../../coding/Python/python_base/ch07.html">
            
                <a href="../../coding/Python/python_base/ch07.html">
            
                    
                    ch07. Python 程序流程控制
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.8" data-path="../../coding/Python/python_base/ch08.html">
            
                <a href="../../coding/Python/python_base/ch08.html">
            
                    
                    ch08. Python 标准库和扩展库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.9" data-path="../../coding/Python/python_base/ch09.html">
            
                <a href="../../coding/Python/python_base/ch09.html">
            
                    
                    ch09. 常用 Python 标准库
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.10" data-path="../../coding/Python/python_base/ch10.html">
            
                <a href="../../coding/Python/python_base/ch10.html">
            
                    
                    ch10. 函数Python
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.11" data-path="../../coding/Python/python_base/ch11.html">
            
                <a href="../../coding/Python/python_base/ch11.html">
            
                    
                    ch11. 面向对象程序设计
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.12" data-path="../../coding/Python/python_base/ch12.html">
            
                <a href="../../coding/Python/python_base/ch12.html">
            
                    
                    ch12. 文件和异常
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.13" data-path="../../coding/Python/python_base/ch13.html">
            
                <a href="../../coding/Python/python_base/ch13.html">
            
                    
                    ch13. 迭代器和生成器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.1.14" data-path="../../coding/Python/python_base/ch14.html">
            
                <a href="../../coding/Python/python_base/ch14.html">
            
                    
                    ch14. Python 奇技淫巧
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3.2" data-path="../../coding/Python/ThinkPython/">
            
                <a href="../../coding/Python/ThinkPython/">
            
                    
                    ThinkPython
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.2.1" data-path="../../coding/Python/ThinkPython/READ_ME.html">
            
                <a href="../../coding/Python/ThinkPython/READ_ME.html">
            
                    
                    简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.2" data-path="../../coding/Python/ThinkPython/chapter1.html">
            
                <a href="../../coding/Python/ThinkPython/chapter1.html">
            
                    
                    第一章 编程之路
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.3" data-path="../../coding/Python/ThinkPython/chapter2.html">
            
                <a href="../../coding/Python/ThinkPython/chapter2.html">
            
                    
                    第二章 变量，表达式，语句
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.4" data-path="../../coding/Python/ThinkPython/chapter3.html">
            
                <a href="../../coding/Python/ThinkPython/chapter3.html">
            
                    
                    第三章 函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.5" data-path="../../coding/Python/ThinkPython/chapter4.html">
            
                <a href="../../coding/Python/ThinkPython/chapter4.html">
            
                    
                    第四章 案例学习：交互设计
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.6" data-path="../../coding/Python/ThinkPython/chapter5.html">
            
                <a href="../../coding/Python/ThinkPython/chapter5.html">
            
                    
                    第五章 条件循环
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.7" data-path="../../coding/Python/ThinkPython/chapter6.html">
            
                <a href="../../coding/Python/ThinkPython/chapter6.html">
            
                    
                    第六章 有返回值的函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.8" data-path="../../coding/Python/ThinkPython/chapter7.html">
            
                <a href="../../coding/Python/ThinkPython/chapter7.html">
            
                    
                    第七章 迭代
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.9" data-path="../../coding/Python/ThinkPython/chapter8.html">
            
                <a href="../../coding/Python/ThinkPython/chapter8.html">
            
                    
                    第八章 字符串
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.10" data-path="../../coding/Python/ThinkPython/chapter9.html">
            
                <a href="../../coding/Python/ThinkPython/chapter9.html">
            
                    
                    第九章 案例学习：单词游戏
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.11" data-path="../../coding/Python/ThinkPython/chapter10.html">
            
                <a href="../../coding/Python/ThinkPython/chapter10.html">
            
                    
                    第十章 列表
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.12" data-path="../../coding/Python/ThinkPython/chapter11.html">
            
                <a href="../../coding/Python/ThinkPython/chapter11.html">
            
                    
                    第十一章 字典
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.13" data-path="../../coding/Python/ThinkPython/chapter12.html">
            
                <a href="../../coding/Python/ThinkPython/chapter12.html">
            
                    
                    第十二章 元组
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.14" data-path="../../coding/Python/ThinkPython/chapter13.html">
            
                <a href="../../coding/Python/ThinkPython/chapter13.html">
            
                    
                    第十三章 案例学习：数据结构的选择
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.15" data-path="../../coding/Python/ThinkPython/chapter14.html">
            
                <a href="../../coding/Python/ThinkPython/chapter14.html">
            
                    
                    第十四章 文件
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.16" data-path="../../coding/Python/ThinkPython/chapter15.html">
            
                <a href="../../coding/Python/ThinkPython/chapter15.html">
            
                    
                    第十五章 类和对象
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.17" data-path="../../coding/Python/ThinkPython/chapter16.html">
            
                <a href="../../coding/Python/ThinkPython/chapter16.html">
            
                    
                    第十六章 类和函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.18" data-path="../../coding/Python/ThinkPython/chapter17.html">
            
                <a href="../../coding/Python/ThinkPython/chapter17.html">
            
                    
                    第十七章 类和方法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.19" data-path="../../coding/Python/ThinkPython/chapter18.html">
            
                <a href="../../coding/Python/ThinkPython/chapter18.html">
            
                    
                    第十八章 继承
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.2.20" data-path="../../coding/Python/ThinkPython/chapter19.html">
            
                <a href="../../coding/Python/ThinkPython/chapter19.html">
            
                    
                    第十九章 更多功能
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5.3.3" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/">
            
                    
                    Learn More Python 3 The Hard Way
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.3.3.1" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/READ_ME.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/READ_ME.html">
            
                    
                    笨办法学 Python · 续 中文版
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.2" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/intro.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/intro.html">
            
                    
                    引言
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.3" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part1.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part1.html">
            
                    
                    第一部分：预备知识
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.4" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex0.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex0.html">
            
                    
                    练习 0：起步
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.5" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex1.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex1.html">
            
                    
                    练习 1：流程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.6" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex2.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex2.html">
            
                    
                    练习 2：创造力
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.7" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex3.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex3.html">
            
                    
                    练习 3：质量
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.8" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part2.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part2.html">
            
                    
                    第二部分：简单的黑魔法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.9" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex4.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex4.html">
            
                    
                    练习 4：处理命令行参数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.10" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex5.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex5.html">
            
                    
                    练习 5：cat
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.11" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex6.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex6.html">
            
                    
                    练习 6：find
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.12" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex7.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex7.html">
            
                    
                    练习 7：grep
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.13" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex8.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex8.html">
            
                    
                    练习 8：cut
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.14" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex9.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex9.html">
            
                    
                    练习 9：sed
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.15" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex10.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex10.html">
            
                    
                    练习 10：sort
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.16" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex11.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex11.html">
            
                    
                    练习 11：uniq
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.17" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex12.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex12.html">
            
                    
                    练习 12：复习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.18" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part3.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part3.html">
            
                    
                    第三部分：数据结构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.19" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex13.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex13.html">
            
                    
                    练习 13：单链表
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.20" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex14.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex14.html">
            
                    
                    练习 14：双链表
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.21" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex15.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex15.html">
            
                    
                    练习 15：栈和队列
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.22" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex16.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex16.html">
            
                    
                    练习 16：冒泡、快速和归并排序
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.23" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex17.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex17.html">
            
                    
                    练习 17：字典
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.24" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex18.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex18.html">
            
                    
                    练习 18：性能测量
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.25" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex19.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex19.html">
            
                    
                    练习 19：改善性能
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.26" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex20.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex20.html">
            
                    
                    练习 20：二叉搜索树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.27" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex21.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex21.html">
            
                    
                    练习 21：二分搜索
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.28" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex22.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex22.html">
            
                    
                    练习 22：后缀数组
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.29" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex23.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex23.html">
            
                    
                    练习 23：三叉搜索树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.30" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex24.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex24.html">
            
                    
                    练习 24：URL 快速路由
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.31" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part4.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part4.html">
            
                    
                    第四部分：进阶项目
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.32" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex25.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex25.html">
            
                    
                    练习 25：xargs
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.33" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex26.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex26.html">
            
                    
                    练习 26：hexdump
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.34" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex27.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex27.html">
            
                    
                    练习 27：tr
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.35" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex28.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex28.html">
            
                    
                    练习 28：sh
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.36" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex29.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex29.html">
            
                    
                    练习 29：diff和patch
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.37" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part5.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part5.html">
            
                    
                    第五部分：文本解析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.38" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex30.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex30.html">
            
                    
                    练习 30：有限状态机
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.39" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex31.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex31.html">
            
                    
                    练习 31：正则表达式
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.40" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex32.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex32.html">
            
                    
                    练习 32：扫描器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.41" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex33.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex33.html">
            
                    
                    练习 33：解析器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.42" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex34.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex34.html">
            
                    
                    练习 34：分析器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.43" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex35.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex35.html">
            
                    
                    练习 35：解释器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.44" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex36.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex36.html">
            
                    
                    练习 36：简单的计算器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.45" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex37.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex37.html">
            
                    
                    练习 37：小型 BASIC
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.46" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part6.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part6.html">
            
                    
                    第六部分：SQL 和对象关系映射
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.47" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex38.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex38.html">
            
                    
                    练习 38：SQL 简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.48" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex39.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex39.html">
            
                    
                    练习 39：SQL 创建
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.49" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex40.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex40.html">
            
                    
                    练习 40：SQL 读取
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.50" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex41.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex41.html">
            
                    
                    练习 41：SQL 更新
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.51" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex42.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex42.html">
            
                    
                    练习 42：SQL 删除
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.52" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex43.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex43.html">
            
                    
                    练习 43：SQL 管理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.53" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex44.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex44.html">
            
                    
                    练习 44：使用 Python 的数据库 API
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.54" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex45.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex45.html">
            
                    
                    练习 45：创建 ORM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.55" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part7.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/part7.html">
            
                    
                    第七部分：大作业
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.56" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex46.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex46.html">
            
                    
                    练习 46：blog
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.57" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex47.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex47.html">
            
                    
                    练习 47：bc
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.58" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex48.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex48.html">
            
                    
                    练习 48：ed
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.59" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex49.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex49.html">
            
                    
                    练习 49：sed
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.60" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex50.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex50.html">
            
                    
                    练习 50：vi
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.61" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex51.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex51.html">
            
                    
                    练习 51：lessweb
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3.3.62" data-path="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex52.html">
            
                <a href="../../coding/Python/Learn_More_Python_3_The_Hard_Way/ex52.html">
            
                    
                    练习 52：moreweb
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" data-path="../../algorithms/">
            
                <a href="../../algorithms/">
            
                    
                    算法汇总
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../../algorithms/base_algo/">
            
                <a href="../../algorithms/base_algo/">
            
                    
                    算法系统
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.1" data-path="../../algorithms/base_algo/hello_algo/">
            
                <a href="../../algorithms/base_algo/hello_algo/">
            
                    
                    Hello 算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.1.1" data-path="../../algorithms/base_algo/hello_algo/chapter_preface/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_preface/">
            
                    
                    前言
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.2" data-path="../../algorithms/base_algo/hello_algo/chapter_introduction/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_introduction/">
            
                    
                    初识算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.3" data-path="../../algorithms/base_algo/hello_algo/chapter_computational_complexity/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_computational_complexity/">
            
                    
                    复杂度分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.4" data-path="../../algorithms/base_algo/hello_algo/chapter_data_structure/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_data_structure/">
            
                    
                    数据结构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.5" data-path="../../algorithms/base_algo/hello_algo/chapter_array_and_linkedlist/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_array_and_linkedlist/">
            
                    
                    数组与链表
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.6" data-path="../../algorithms/base_algo/hello_algo/chapter_stack_and_queue/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_stack_and_queue/">
            
                    
                    栈与队列
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.7" data-path="../../algorithms/base_algo/hello_algo/chapter_hashing/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_hashing/">
            
                    
                    哈希表
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.8" data-path="../../algorithms/base_algo/hello_algo/chapter_tree/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_tree/">
            
                    
                    树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.9" data-path="../../algorithms/base_algo/hello_algo/chapter_heap/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_heap/">
            
                    
                    堆
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.10" data-path="../../algorithms/base_algo/hello_algo/chapter_graph/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_graph/">
            
                    
                    图
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.11" data-path="../../algorithms/base_algo/hello_algo/chapter_searching/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_searching/">
            
                    
                    搜索
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.12" data-path="../../algorithms/base_algo/hello_algo/chapter_sorting/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_sorting/">
            
                    
                    排序
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.13" data-path="../../algorithms/base_algo/hello_algo/chapter_divide_and_conquer/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_divide_and_conquer/">
            
                    
                    分治
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.14" data-path="../../algorithms/base_algo/hello_algo/chapter_backtracking/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_backtracking/">
            
                    
                    回溯
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.15" data-path="../../algorithms/base_algo/hello_algo/chapter_dynamic_programming/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_dynamic_programming/">
            
                    
                    动态规划
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.16" data-path="../../algorithms/base_algo/hello_algo/chapter_greedy/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_greedy/">
            
                    
                    贪心
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.1.17" data-path="../../algorithms/base_algo/hello_algo/chapter_appendix/">
            
                <a href="../../algorithms/base_algo/hello_algo/chapter_appendix/">
            
                    
                    附录
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.1.2" data-path="../../algorithms/base_algo/Algorithms_note.html">
            
                <a href="../../algorithms/base_algo/Algorithms_note.html">
            
                    
                    算法笔记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3" data-path="../../algorithms/base_algo/acm-md/">
            
                <a href="../../algorithms/base_algo/acm-md/">
            
                    
                    ACM算法指南
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.3.1" data-path="../../algorithms/base_algo/acm-md/数据结构/基础数据结构.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/基础数据结构.html">
            
                    
                    基础数据结构
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.3.1.1" data-path="../../algorithms/base_algo/acm-md/数据结构/高级数据结构概述.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/高级数据结构概述.html">
            
                    
                    高级数据结构
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.2" data-path="../../algorithms/base_algo/acm-md/数据结构/并查集.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/并查集.html">
            
                    
                    并查集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.3" data-path="../../algorithms/base_algo/acm-md/数据结构/单调栈和单调队列.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/单调栈和单调队列.html">
            
                    
                    单调栈/单调队列
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.4" data-path="../../algorithms/base_algo/acm-md/数据结构/线段树.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/线段树.html">
            
                    
                    线段树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.5" data-path="../../algorithms/base_algo/acm-md/数据结构/线段树懒标记.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/线段树懒标记.html">
            
                    
                    线段树懒标记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.6" data-path="../../algorithms/base_algo/acm-md/数据结构/树状数组.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/树状数组.html">
            
                    
                    树状数组
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.7" data-path="../../algorithms/base_algo/acm-md/数据结构/ST表.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/ST表.html">
            
                    
                    ST表
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.8" data-path="../../algorithms/base_algo/acm-md/数据结构/堆.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/堆.html">
            
                    
                    堆
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.9" data-path="../../algorithms/base_algo/acm-md/数据结构/二叉树.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/二叉树.html">
            
                    
                    二叉树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.10" data-path="../../algorithms/base_algo/acm-md/数据结构/红黑树.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/红黑树.html">
            
                    
                    红黑树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.11" data-path="../../algorithms/base_algo/acm-md/数据结构/跳表.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/跳表.html">
            
                    
                    跳表
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.12" data-path="../../algorithms/base_algo/acm-md/数据结构/平衡树.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/平衡树.html">
            
                    
                    平衡树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.1.13" data-path="../../algorithms/base_algo/acm-md/数据结构/分块算法.html">
            
                <a href="../../algorithms/base_algo/acm-md/数据结构/分块算法.html">
            
                    
                    分块算法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.2" data-path="../../algorithms/base_algo/acm-md/搜索算法/搜索算法概述.html">
            
                <a href="../../algorithms/base_algo/acm-md/搜索算法/搜索算法概述.html">
            
                    
                    搜索算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.3.2.1" data-path="../../algorithms/base_algo/acm-md/搜索算法/深度优先搜索.html">
            
                <a href="../../algorithms/base_algo/acm-md/搜索算法/深度优先搜索.html">
            
                    
                    深度优先搜索(DFS)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.2.2" data-path="../../algorithms/base_algo/acm-md/搜索算法/广度优先搜索.html">
            
                <a href="../../algorithms/base_algo/acm-md/搜索算法/广度优先搜索.html">
            
                    
                    广度优先搜索(BFS)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.2.3" data-path="../../algorithms/base_algo/acm-md/搜索算法/二分查找.html">
            
                <a href="../../algorithms/base_algo/acm-md/搜索算法/二分查找.html">
            
                    
                    二分查找
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.2.4" data-path="../../algorithms/base_algo/acm-md/搜索算法/回溯法.html">
            
                <a href="../../algorithms/base_algo/acm-md/搜索算法/回溯法.html">
            
                    
                    回溯法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.3" data-path="../../algorithms/base_algo/acm-md/图论算法/图论概述.html">
            
                <a href="../../algorithms/base_algo/acm-md/图论算法/图论概述.html">
            
                    
                    图论算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.3.3.1" data-path="../../algorithms/base_algo/acm-md/图论算法/图的表示.html">
            
                <a href="../../algorithms/base_algo/acm-md/图论算法/图的表示.html">
            
                    
                    图的表示
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.3.2" data-path="../../algorithms/base_algo/acm-md/图论算法/最短路径算法.html">
            
                <a href="../../algorithms/base_algo/acm-md/图论算法/最短路径算法.html">
            
                    
                    最短路径算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.3.3" data-path="../../algorithms/base_algo/acm-md/图论算法/最小生成树.html">
            
                <a href="../../algorithms/base_algo/acm-md/图论算法/最小生成树.html">
            
                    
                    最小生成树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.3.4" data-path="../../algorithms/base_algo/acm-md/图论算法/拓扑排序.html">
            
                <a href="../../algorithms/base_algo/acm-md/图论算法/拓扑排序.html">
            
                    
                    拓扑排序
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.4" data-path="../../algorithms/base_algo/acm-md/动态规划/动态规划概述.html">
            
                <a href="../../algorithms/base_algo/acm-md/动态规划/动态规划概述.html">
            
                    
                    动态规划
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.3.4.1" data-path="../../algorithms/base_algo/acm-md/动态规划/动态规划基础.html">
            
                <a href="../../algorithms/base_algo/acm-md/动态规划/动态规划基础.html">
            
                    
                    动态规划基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.4.2" data-path="../../algorithms/base_algo/acm-md/动态规划/背包问题.html">
            
                <a href="../../algorithms/base_algo/acm-md/动态规划/背包问题.html">
            
                    
                    背包问题
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.4.3" data-path="../../algorithms/base_algo/acm-md/动态规划/最长公共子序列.html">
            
                <a href="../../algorithms/base_algo/acm-md/动态规划/最长公共子序列.html">
            
                    
                    最长公共子序列
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.4.4" data-path="../../algorithms/base_algo/acm-md/动态规划/最长递增子序列.html">
            
                <a href="../../algorithms/base_algo/acm-md/动态规划/最长递增子序列.html">
            
                    
                    最长递增子序列
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.5" data-path="../../algorithms/base_algo/acm-md/字符串算法/字符串算法概述.html">
            
                <a href="../../algorithms/base_algo/acm-md/字符串算法/字符串算法概述.html">
            
                    
                    字符串算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.3.5.1" data-path="../../algorithms/base_algo/acm-md/字符串算法/字符串匹配.html">
            
                <a href="../../algorithms/base_algo/acm-md/字符串算法/字符串匹配.html">
            
                    
                    字符串匹配
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.5.2" data-path="../../algorithms/base_algo/acm-md/字符串算法/KMP算法.html">
            
                <a href="../../algorithms/base_algo/acm-md/字符串算法/KMP算法.html">
            
                    
                    KMP算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.5.3" data-path="../../algorithms/base_algo/acm-md/字符串算法/字典树.html">
            
                <a href="../../algorithms/base_algo/acm-md/字符串算法/字典树.html">
            
                    
                    字典树(Trie)
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.6" data-path="../../algorithms/base_algo/acm-md/数学算法/数学算法概述.html">
            
                <a href="../../algorithms/base_algo/acm-md/数学算法/数学算法概述.html">
            
                    
                    数学算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.3.6.1" data-path="../../algorithms/base_algo/acm-md/数学算法/素数筛法.md">
            
                <span>
            
                    
                    素数筛法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.6.2" data-path="../../algorithms/base_algo/acm-md/数学算法/快速幂.html">
            
                <a href="../../algorithms/base_algo/acm-md/数学算法/快速幂.html">
            
                    
                    快速幂
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.6.3" data-path="../../algorithms/base_algo/acm-md/数学算法/最大公约数与最小公倍数.html">
            
                <a href="../../algorithms/base_algo/acm-md/数学算法/最大公约数与最小公倍数.html">
            
                    
                    最大公约数与最小公倍数
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.7" data-path="../../algorithms/base_algo/acm-md/技巧与优化/技巧与优化概述.html">
            
                <a href="../../algorithms/base_algo/acm-md/技巧与优化/技巧与优化概述.html">
            
                    
                    技巧与优化
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.3.7.1" data-path="../../algorithms/base_algo/acm-md/技巧与优化/位运算技巧.html">
            
                <a href="../../algorithms/base_algo/acm-md/技巧与优化/位运算技巧.html">
            
                    
                    位运算技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.7.2" data-path="../../algorithms/base_algo/acm-md/技巧与优化/STL使用技巧.html">
            
                <a href="../../algorithms/base_algo/acm-md/技巧与优化/STL使用技巧.html">
            
                    
                    STL使用技巧
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.7.3" data-path="../../algorithms/base_algo/acm-md/技巧与优化/常见算法优化思路.html">
            
                <a href="../../algorithms/base_algo/acm-md/技巧与优化/常见算法优化思路.html">
            
                    
                    常见算法优化思路
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.8" data-path="../../algorithms/base_algo/acm-md/实战练习指导/实战练习概述.html">
            
                <a href="../../algorithms/base_algo/acm-md/实战练习指导/实战练习概述.html">
            
                    
                    实战练习指导
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1.3.8.1" data-path="../../algorithms/base_algo/acm-md/实战练习指导/如何分析问题.html">
            
                <a href="../../algorithms/base_algo/acm-md/实战练习指导/如何分析问题.html">
            
                    
                    如何分析问题
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.8.2" data-path="../../algorithms/base_algo/acm-md/实战练习指导/常见解题模板.html">
            
                <a href="../../algorithms/base_algo/acm-md/实战练习指导/常见解题模板.html">
            
                    
                    常见解题模板
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.8.3" data-path="../../algorithms/base_algo/acm-md/实战练习指导/算法比赛技巧.html">
            
                <a href="../../algorithms/base_algo/acm-md/实战练习指导/算法比赛技巧.html">
            
                    
                    算法比赛技巧
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.9" data-path="../../algorithms/base_algo/acm-md/算法函数.html">
            
                <a href="../../algorithms/base_algo/acm-md/算法函数.html">
            
                    
                    算法函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.10" data-path="../../algorithms/base_algo/acm-md/ACM常用算法.html">
            
                <a href="../../algorithms/base_algo/acm-md/ACM常用算法.html">
            
                    
                    ACM常用算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.11" data-path="../../algorithms/base_algo/acm-md/STL常用函数.html">
            
                <a href="../../algorithms/base_algo/acm-md/STL常用函数.html">
            
                    
                    STL常用函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.12" data-path="../../algorithms/base_algo/acm-md/stl容器.html">
            
                <a href="../../algorithms/base_algo/acm-md/stl容器.html">
            
                    
                    stl容器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.1.3.13" data-path="../../algorithms/base_algo/acm-md/string.html">
            
                <a href="../../algorithms/base_algo/acm-md/string.html">
            
                    
                    string
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../../algorithms/ai/">
            
                <a href="../../algorithms/ai/">
            
                    
                    人工智能
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1" data-path="../../algorithms/ai/d2l.html">
            
                <a href="../../algorithms/ai/d2l.html">
            
                    
                    动手学深度学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.1" data-path="../../algorithms/ai/d2l/chapter_preface/">
            
                <a href="../../algorithms/ai/d2l/chapter_preface/">
            
                    
                    前言
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.2" data-path="../../algorithms/ai/d2l/chapter_installation/">
            
                <a href="../../algorithms/ai/d2l/chapter_installation/">
            
                    
                    安装
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.3" data-path="../../algorithms/ai/d2l/chapter_notation/">
            
                <a href="../../algorithms/ai/d2l/chapter_notation/">
            
                    
                    符号
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.4" data-path="../../algorithms/ai/d2l/chapter_introduction/">
            
                <a href="../../algorithms/ai/d2l/chapter_introduction/">
            
                    
                    1. 引言
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.5" data-path="../../algorithms/ai/d2l/chapter_preliminaries/">
            
                <a href="../../algorithms/ai/d2l/chapter_preliminaries/">
            
                    
                    2. 预备知识
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.5.1" data-path="../../algorithms/ai/d2l/chapter_preliminaries/ndarray.html">
            
                <a href="../../algorithms/ai/d2l/chapter_preliminaries/ndarray.html">
            
                    
                    2.1. 数据操作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.5.2" data-path="../../algorithms/ai/d2l/chapter_preliminaries/pandas.html">
            
                <a href="../../algorithms/ai/d2l/chapter_preliminaries/pandas.html">
            
                    
                    2.2. 数据预处理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.5.3" data-path="../../algorithms/ai/d2l/chapter_preliminaries/linear-algebra.html">
            
                <a href="../../algorithms/ai/d2l/chapter_preliminaries/linear-algebra.html">
            
                    
                    2.3. 线性代数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.5.4" data-path="../../algorithms/ai/d2l/chapter_preliminaries/calculus.html">
            
                <a href="../../algorithms/ai/d2l/chapter_preliminaries/calculus.html">
            
                    
                    2.4. 微积分
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.5.5" data-path="../../algorithms/ai/d2l/chapter_preliminaries/autograd.html">
            
                <a href="../../algorithms/ai/d2l/chapter_preliminaries/autograd.html">
            
                    
                    2.5. 自动微分
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.5.6" data-path="../../algorithms/ai/d2l/chapter_preliminaries/probability.html">
            
                <a href="../../algorithms/ai/d2l/chapter_preliminaries/probability.html">
            
                    
                    2.6. 概率
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.5.7" data-path="../../algorithms/ai/d2l/chapter_preliminaries/lookup-api.html">
            
                <a href="../../algorithms/ai/d2l/chapter_preliminaries/lookup-api.html">
            
                    
                    2.7. 查阅文档
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.6" data-path="../../algorithms/ai/d2l/chapter_linear-networks/">
            
                <a href="../../algorithms/ai/d2l/chapter_linear-networks/">
            
                    
                    3. 线性神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.6.1" data-path="../../algorithms/ai/d2l/chapter_linear-networks/linear-regression.html">
            
                <a href="../../algorithms/ai/d2l/chapter_linear-networks/linear-regression.html">
            
                    
                    3.1. 线性回归
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.6.2" data-path="../../algorithms/ai/d2l/chapter_linear-networks/linear-regression-scratch.html">
            
                <a href="../../algorithms/ai/d2l/chapter_linear-networks/linear-regression-scratch.html">
            
                    
                    3.2. 线性回归的从零开始实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.6.3" data-path="../../algorithms/ai/d2l/chapter_linear-networks/linear-regression-concise.html">
            
                <a href="../../algorithms/ai/d2l/chapter_linear-networks/linear-regression-concise.html">
            
                    
                    3.3. 线性回归的简洁实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.6.4" data-path="../../algorithms/ai/d2l/chapter_linear-networks/softmax-regression.html">
            
                <a href="../../algorithms/ai/d2l/chapter_linear-networks/softmax-regression.html">
            
                    
                    3.4. softmax回归
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.6.5" data-path="../../algorithms/ai/d2l/chapter_linear-networks/image-classification-dataset.html">
            
                <a href="../../algorithms/ai/d2l/chapter_linear-networks/image-classification-dataset.html">
            
                    
                    3.5. 图像分类数据集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.6.6" data-path="../../algorithms/ai/d2l/chapter_linear-networks/softmax-regression-scratch.html">
            
                <a href="../../algorithms/ai/d2l/chapter_linear-networks/softmax-regression-scratch.html">
            
                    
                    3.6. softmax回归的从零开始实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.6.7" data-path="../../algorithms/ai/d2l/chapter_linear-networks/softmax-regression-concise.html">
            
                <a href="../../algorithms/ai/d2l/chapter_linear-networks/softmax-regression-concise.html">
            
                    
                    3.7. softmax回归的简洁实现
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.7" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/">
            
                    
                    4. 多层感知机
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.7.1" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/mlp.html">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/mlp.html">
            
                    
                    4.1. 多层感知机
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.7.2" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/mlp-scratch.html">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/mlp-scratch.html">
            
                    
                    4.2. 多层感知机的从零开始实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.7.3" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/mlp-concise.html">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/mlp-concise.html">
            
                    
                    4.3. 多层感知机的简洁实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.7.4" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/underfit-overfit.html">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/underfit-overfit.html">
            
                    
                    4.4. 模型选择、欠拟合和过拟合
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.7.5" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/weight-decay.html">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/weight-decay.html">
            
                    
                    4.5. 权重衰减
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.7.6" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/dropout.html">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/dropout.html">
            
                    
                    4.6. 暂退法（Dropout）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.7.7" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/backprop.html">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/backprop.html">
            
                    
                    4.7. 前向传播、反向传播和计算图
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.7.8" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/numerical-stability-and-init.html">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/numerical-stability-and-init.html">
            
                    
                    4.8. 数值稳定性和模型初始化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.7.9" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/environment.html">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/environment.html">
            
                    
                    4.9. 环境和分布偏移
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.7.10" data-path="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/kaggle-house-price.html">
            
                <a href="../../algorithms/ai/d2l/chapter_multilayer-perceptrons/kaggle-house-price.html">
            
                    
                    4.10. 实战Kaggle比赛：预测房价
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.8" data-path="../../algorithms/ai/d2l/chapter_deep-learning-computation/">
            
                <a href="../../algorithms/ai/d2l/chapter_deep-learning-computation/">
            
                    
                    5. 深度学习计算
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.8.1" data-path="../../algorithms/ai/d2l/chapter_deep-learning-computation/model-construction.html">
            
                <a href="../../algorithms/ai/d2l/chapter_deep-learning-computation/model-construction.html">
            
                    
                    5.1. 层和块
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.8.2" data-path="../../algorithms/ai/d2l/chapter_deep-learning-computation/parameters.html">
            
                <a href="../../algorithms/ai/d2l/chapter_deep-learning-computation/parameters.html">
            
                    
                    5.2. 参数管理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.8.3" data-path="../../algorithms/ai/d2l/chapter_deep-learning-computation/deferred-init.html">
            
                <a href="../../algorithms/ai/d2l/chapter_deep-learning-computation/deferred-init.html">
            
                    
                    5.3. 延后初始化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.8.4" data-path="../../algorithms/ai/d2l/chapter_deep-learning-computation/custom-layer.html">
            
                <a href="../../algorithms/ai/d2l/chapter_deep-learning-computation/custom-layer.html">
            
                    
                    5.4. 自定义层
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.8.5" data-path="../../algorithms/ai/d2l/chapter_deep-learning-computation/read-write.html">
            
                <a href="../../algorithms/ai/d2l/chapter_deep-learning-computation/read-write.html">
            
                    
                    5.5. 读写文件
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.8.6" data-path="../../algorithms/ai/d2l/chapter_deep-learning-computation/use-gpu.html">
            
                <a href="../../algorithms/ai/d2l/chapter_deep-learning-computation/use-gpu.html">
            
                    
                    5.6. GPU计算
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.9" data-path="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/">
            
                    
                    6. 卷积神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.9.1" data-path="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/why-conv.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/why-conv.html">
            
                    
                    6.1. 从全连接层到卷积
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.9.2" data-path="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/conv-layer.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/conv-layer.html">
            
                    
                    6.2. 图像卷积
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.9.3" data-path="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/padding-and-strides.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/padding-and-strides.html">
            
                    
                    6.3. 填充和步幅
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.9.4" data-path="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/channels.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/channels.html">
            
                    
                    6.4. 多输入多输出通道
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.9.5" data-path="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/pooling.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/pooling.html">
            
                    
                    6.5. 汇聚层
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.9.6" data-path="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/lenet.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-neural-networks/lenet.html">
            
                    
                    6.6. 卷积神经网络（LeNet）
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.10" data-path="../../algorithms/ai/d2l/chapter_convolutional-modern/">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-modern/">
            
                    
                    7. 现代卷积神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.10.1" data-path="../../algorithms/ai/d2l/chapter_convolutional-modern/alexnet.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-modern/alexnet.html">
            
                    
                    7.1. 深度卷积神经网络（AlexNet）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.10.2" data-path="../../algorithms/ai/d2l/chapter_convolutional-modern/vgg.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-modern/vgg.html">
            
                    
                    7.2. 使用块的网络（VGG）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.10.3" data-path="../../algorithms/ai/d2l/chapter_convolutional-modern/nin.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-modern/nin.html">
            
                    
                    7.3. 网络中的网络（NiN）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.10.4" data-path="../../algorithms/ai/d2l/chapter_convolutional-modern/googlenet.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-modern/googlenet.html">
            
                    
                    7.4. 含并行连结的网络（GoogLeNet）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.10.5" data-path="../../algorithms/ai/d2l/chapter_convolutional-modern/batch-norm.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-modern/batch-norm.html">
            
                    
                    7.5. 批量规范化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.10.6" data-path="../../algorithms/ai/d2l/chapter_convolutional-modern/resnet.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-modern/resnet.html">
            
                    
                    7.6. 残差网络（ResNet）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.10.7" data-path="../../algorithms/ai/d2l/chapter_convolutional-modern/densenet.html">
            
                <a href="../../algorithms/ai/d2l/chapter_convolutional-modern/densenet.html">
            
                    
                    7.7. 稠密连接网络（DenseNet）
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.11" data-path="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/">
            
                    
                    8. 循环神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.11.1" data-path="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/sequence.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/sequence.html">
            
                    
                    8.1. 序列模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.11.2" data-path="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/text-preprocessing.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/text-preprocessing.html">
            
                    
                    8.2. 文本预处理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.11.3" data-path="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/language-models-and-dataset.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/language-models-and-dataset.html">
            
                    
                    8.3. 语言模型和数据集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.11.4" data-path="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/rnn.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/rnn.html">
            
                    
                    8.4. 循环神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.11.5" data-path="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/rnn-scratch.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/rnn-scratch.html">
            
                    
                    8.5. 循环神经网络的从零开始实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.11.6" data-path="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/rnn-concise.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/rnn-concise.html">
            
                    
                    8.6. 循环神经网络的简洁实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.11.7" data-path="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/bptt.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-neural-networks/bptt.html">
            
                    
                    8.7. 通过时间反向传播
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.12" data-path="../../algorithms/ai/d2l/chapter_recurrent-modern/">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-modern/">
            
                    
                    9. 现代循环神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.12.1" data-path="../../algorithms/ai/d2l/chapter_recurrent-modern/gru.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-modern/gru.html">
            
                    
                    9.1. 门控循环单元（GRU）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.12.2" data-path="../../algorithms/ai/d2l/chapter_recurrent-modern/lstm.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-modern/lstm.html">
            
                    
                    9.2. 长短期记忆（LSTM）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.12.3" data-path="../../algorithms/ai/d2l/chapter_recurrent-modern/deep-rnn.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-modern/deep-rnn.html">
            
                    
                    9.3. 深度循环神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.12.4" data-path="../../algorithms/ai/d2l/chapter_recurrent-modern/bi-rnn.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-modern/bi-rnn.html">
            
                    
                    9.4. 双向循环神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.12.5" data-path="../../algorithms/ai/d2l/chapter_recurrent-modern/machine-translation-and-dataset.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-modern/machine-translation-and-dataset.html">
            
                    
                    9.5. 机器翻译及数据集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.12.6" data-path="../../algorithms/ai/d2l/chapter_recurrent-modern/encoder-decoder.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-modern/encoder-decoder.html">
            
                    
                    9.6. 编码器—解码器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.12.7" data-path="../../algorithms/ai/d2l/chapter_recurrent-modern/seq2seq.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-modern/seq2seq.html">
            
                    
                    9.7. 序列到序列学习（seq2seq）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.12.8" data-path="../../algorithms/ai/d2l/chapter_recurrent-modern/beam-search.html">
            
                <a href="../../algorithms/ai/d2l/chapter_recurrent-modern/beam-search.html">
            
                    
                    9.8. 束搜索
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.13" data-path="../../algorithms/ai/d2l/chapter_attention-mechanisms/">
            
                <a href="../../algorithms/ai/d2l/chapter_attention-mechanisms/">
            
                    
                    10. 注意力机制
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.13.1" data-path="../../algorithms/ai/d2l/chapter_attention-mechanisms/attention-cues.html">
            
                <a href="../../algorithms/ai/d2l/chapter_attention-mechanisms/attention-cues.html">
            
                    
                    10.1. 注意力提示
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.13.2" data-path="../../algorithms/ai/d2l/chapter_attention-mechanisms/nadaraya-waston.html">
            
                <a href="../../algorithms/ai/d2l/chapter_attention-mechanisms/nadaraya-waston.html">
            
                    
                    10.2. 注意力汇聚：Nadaraya-Watson 核回归
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.13.3" data-path="../../algorithms/ai/d2l/chapter_attention-mechanisms/attention-scoring-functions.html">
            
                <a href="../../algorithms/ai/d2l/chapter_attention-mechanisms/attention-scoring-functions.html">
            
                    
                    10.3. 注意力评分函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.13.4" data-path="../../algorithms/ai/d2l/chapter_attention-mechanisms/bahdanau-attention.html">
            
                <a href="../../algorithms/ai/d2l/chapter_attention-mechanisms/bahdanau-attention.html">
            
                    
                    10.4. Bahdanau 注意力
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.13.5" data-path="../../algorithms/ai/d2l/chapter_attention-mechanisms/multihead-attention.html">
            
                <a href="../../algorithms/ai/d2l/chapter_attention-mechanisms/multihead-attention.html">
            
                    
                    10.5. 多头注意力
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.13.6" data-path="../../algorithms/ai/d2l/chapter_attention-mechanisms/self-attention-and-positional-encoding.html">
            
                <a href="../../algorithms/ai/d2l/chapter_attention-mechanisms/self-attention-and-positional-encoding.html">
            
                    
                    10.6. 自注意力和位置编码
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.13.7" data-path="../../algorithms/ai/d2l/chapter_attention-mechanisms/transformer.html">
            
                <a href="../../algorithms/ai/d2l/chapter_attention-mechanisms/transformer.html">
            
                    
                    10.7. Transformer
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14" data-path="../../algorithms/ai/d2l/chapter_optimization/">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/">
            
                    
                    11. 优化算法
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.14.1" data-path="../../algorithms/ai/d2l/chapter_optimization/optimization-intro.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/optimization-intro.html">
            
                    
                    11.1. 优化与深度学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14.2" data-path="../../algorithms/ai/d2l/chapter_optimization/convexity.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/convexity.html">
            
                    
                    11.2. 凸性
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14.3" data-path="../../algorithms/ai/d2l/chapter_optimization/gd.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/gd.html">
            
                    
                    11.3. 梯度下降
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14.4" data-path="../../algorithms/ai/d2l/chapter_optimization/sgd.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/sgd.html">
            
                    
                    11.4. 随机梯度下降
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14.5" data-path="../../algorithms/ai/d2l/chapter_optimization/minibatch-sgd.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/minibatch-sgd.html">
            
                    
                    11.5. 小批量随机梯度下降
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14.6" data-path="../../algorithms/ai/d2l/chapter_optimization/momentum.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/momentum.html">
            
                    
                    11.6. 动量法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14.7" data-path="../../algorithms/ai/d2l/chapter_optimization/adagrad.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/adagrad.html">
            
                    
                    11.7. AdaGrad算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14.8" data-path="../../algorithms/ai/d2l/chapter_optimization/rmsprop.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/rmsprop.html">
            
                    
                    11.8. RMSProp算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14.9" data-path="../../algorithms/ai/d2l/chapter_optimization/adadelta.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/adadelta.html">
            
                    
                    11.9. Adadelta
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14.10" data-path="../../algorithms/ai/d2l/chapter_optimization/adam.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/adam.html">
            
                    
                    11.10. Adam算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.14.11" data-path="../../algorithms/ai/d2l/chapter_optimization/lr-scheduler.html">
            
                <a href="../../algorithms/ai/d2l/chapter_optimization/lr-scheduler.html">
            
                    
                    11.11. 学习率调度器
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.15" data-path="../../algorithms/ai/d2l/chapter_computational-performance/">
            
                <a href="../../algorithms/ai/d2l/chapter_computational-performance/">
            
                    
                    12. 计算性能
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.15.1" data-path="../../algorithms/ai/d2l/chapter_computational-performance/hybridize.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computational-performance/hybridize.html">
            
                    
                    12.1. 编译器和解释器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.15.2" data-path="../../algorithms/ai/d2l/chapter_computational-performance/async-computation.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computational-performance/async-computation.html">
            
                    
                    12.2. 异步计算
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.15.3" data-path="../../algorithms/ai/d2l/chapter_computational-performance/auto-parallelism.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computational-performance/auto-parallelism.html">
            
                    
                    12.3. 自动并行
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.15.4" data-path="../../algorithms/ai/d2l/chapter_computational-performance/hardware.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computational-performance/hardware.html">
            
                    
                    12.4. 硬件
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.15.5" data-path="../../algorithms/ai/d2l/chapter_computational-performance/multiple-gpus.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computational-performance/multiple-gpus.html">
            
                    
                    12.5. 多GPU训练
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.15.6" data-path="../../algorithms/ai/d2l/chapter_computational-performance/multiple-gpus-concise.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computational-performance/multiple-gpus-concise.html">
            
                    
                    12.6. 多GPU的简洁实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.15.7" data-path="../../algorithms/ai/d2l/chapter_computational-performance/parameterserver.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computational-performance/parameterserver.html">
            
                    
                    12.7. 参数服务器
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16" data-path="../../algorithms/ai/d2l/chapter_computer-vision/">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/">
            
                    
                    13. 计算机视觉
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.16.1" data-path="../../algorithms/ai/d2l/chapter_computer-vision/image-augmentation.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/image-augmentation.html">
            
                    
                    13.1. 图像增广
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.2" data-path="../../algorithms/ai/d2l/chapter_computer-vision/fine-tuning.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/fine-tuning.html">
            
                    
                    13.2. 微调
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.3" data-path="../../algorithms/ai/d2l/chapter_computer-vision/bounding-box.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/bounding-box.html">
            
                    
                    13.3. 目标检测和边界框
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.4" data-path="../../algorithms/ai/d2l/chapter_computer-vision/anchor.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/anchor.html">
            
                    
                    13.4. 锚框
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.5" data-path="../../algorithms/ai/d2l/chapter_computer-vision/multiscale-object-detection.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/multiscale-object-detection.html">
            
                    
                    13.5. 多尺度目标检测
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.6" data-path="../../algorithms/ai/d2l/chapter_computer-vision/object-detection-dataset.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/object-detection-dataset.html">
            
                    
                    13.6. 目标检测数据集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.7" data-path="../../algorithms/ai/d2l/chapter_computer-vision/ssd.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/ssd.html">
            
                    
                    13.7. 单发多框检测（SSD）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.8" data-path="../../algorithms/ai/d2l/chapter_computer-vision/rcnn.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/rcnn.html">
            
                    
                    13.8. 区域卷积神经网络（R-CNN）系列
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.9" data-path="../../algorithms/ai/d2l/chapter_computer-vision/semantic-segmentation-and-dataset.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/semantic-segmentation-and-dataset.html">
            
                    
                    13.9. 语义分割和数据集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.10" data-path="../../algorithms/ai/d2l/chapter_computer-vision/transposed-conv.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/transposed-conv.html">
            
                    
                    13.10. 转置卷积
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.11" data-path="../../algorithms/ai/d2l/chapter_computer-vision/fcn.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/fcn.html">
            
                    
                    13.11. 全卷积网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.12" data-path="../../algorithms/ai/d2l/chapter_computer-vision/neural-style.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/neural-style.html">
            
                    
                    13.12. 风格迁移
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.13" data-path="../../algorithms/ai/d2l/chapter_computer-vision/kaggle-cifar10.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/kaggle-cifar10.html">
            
                    
                    13.13. 实战 Kaggle 比赛：图像分类 (CIFAR-10.md)
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.16.14" data-path="../../algorithms/ai/d2l/chapter_computer-vision/kaggle-dog.html">
            
                <a href="../../algorithms/ai/d2l/chapter_computer-vision/kaggle-dog.html">
            
                    
                    13.14. 实战Kaggle比赛：狗的品种识别（ImageNet Dogs）
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.17" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/">
            
                    
                    14. 自然语言处理：预训练
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.17.1" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/word2vec.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/word2vec.html">
            
                    
                    14.1. 词嵌入（word2vec）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.17.2" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/approx-training.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/approx-training.html">
            
                    
                    14.2. 近似训练
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.17.3" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/word-embedding-dataset.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/word-embedding-dataset.html">
            
                    
                    14.3. 用于预训练词嵌入的数据集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.17.4" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/word2vec-pretraining.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/word2vec-pretraining.html">
            
                    
                    14.4. 预训练word2vec
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.17.5" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/glove.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/glove.html">
            
                    
                    14.5. 全局向量的词嵌入（GloVe）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.17.6" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/subword-embedding.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/subword-embedding.html">
            
                    
                    14.6. 子词嵌入
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.17.7" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/similarity-analogy.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/similarity-analogy.html">
            
                    
                    14.7. 词的相似性和类比任务
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.17.8" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/bert.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/bert.html">
            
                    
                    14.8. 来自Transformers的双向编码器表示（BERT）
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.17.9" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/bert-dataset.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/bert-dataset.html">
            
                    
                    14.9. 用于预训练BERT的数据集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.17.10" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/bert-pretraining.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-pretraining/bert-pretraining.html">
            
                    
                    14.10. 预训练BERT
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.18" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/">
            
                    
                    15. 自然语言处理：应用
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.18.1" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/sentiment-analysis-and-dataset.html">
            
                    
                    15.1. 情感分析及数据集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.18.2" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/sentiment-analysis-rnn.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/sentiment-analysis-rnn.html">
            
                    
                    15.2. 情感分析：使用循环神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.18.3" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/sentiment-analysis-cnn.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/sentiment-analysis-cnn.html">
            
                    
                    15.3. 情感分析：使用卷积神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.18.4" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/natural-language-inference-and-dataset.html">
            
                    
                    15.4. 自然语言推断与数据集
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.18.5" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/natural-language-inference-attention.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/natural-language-inference-attention.html">
            
                    
                    15.5. 自然语言推断：使用注意力
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.18.6" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/finetuning-bert.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/finetuning-bert.html">
            
                    
                    15.6. 针对序列级和词元级应用微调BERT
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.18.7" data-path="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/natural-language-inference-bert.html">
            
                <a href="../../algorithms/ai/d2l/chapter_natural-language-processing-applications/natural-language-inference-bert.html">
            
                    
                    15.7. 自然语言推断：微调BERT
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.19" data-path="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/">
            
                <a href="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/">
            
                    
                    16. 附录：深度学习工具
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.1.19.1" data-path="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/jupyter.html">
            
                <a href="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/jupyter.html">
            
                    
                    16.1. 使用Jupyter Notebook
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.19.2" data-path="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/sagemaker.html">
            
                <a href="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/sagemaker.html">
            
                    
                    16.2. 使用Amazon SageMaker
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.19.3" data-path="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/aws.html">
            
                <a href="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/aws.html">
            
                    
                    16.3. 使用Amazon EC2实例
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.19.4" data-path="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html">
            
                <a href="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/selecting-servers-gpus.html">
            
                    
                    16.4. 选择服务器和GPU
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.19.5" data-path="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/contributing.html">
            
                <a href="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/contributing.html">
            
                    
                    16.5. 为本书做贡献
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.19.6" data-path="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/d2l.html">
            
                <a href="../../algorithms/ai/d2l/chapter_appendix-tools-for-deep-learning/d2l.html">
            
                    
                    16.6. d2l API 文档
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.1.20" data-path="../../algorithms/ai/d2l/chapter_references/zreferences.html">
            
                <a href="../../algorithms/ai/d2l/chapter_references/zreferences.html">
            
                    
                    参考文献
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.2" data-path="../../algorithms/ai/ai_math/">
            
                <a href="../../algorithms/ai/ai_math/">
            
                    
                    常见机器学习算法的数学推导
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.2.1" data-path="../../algorithms/ai/ai_math/LinearRegression.html">
            
                <a href="../../algorithms/ai/ai_math/LinearRegression.html">
            
                    
                    线性回归
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.2.2" data-path="../../algorithms/ai/ai_math/LogisticRegression.html">
            
                <a href="../../algorithms/ai/ai_math/LogisticRegression.html">
            
                    
                    逻辑回归
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.2.3" data-path="../../algorithms/ai/ai_math/SimpleBayes.html">
            
                <a href="../../algorithms/ai/ai_math/SimpleBayes.html">
            
                    
                    朴素贝叶斯
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.2.4" data-path="../../algorithms/ai/ai_math/KNN.html">
            
                <a href="../../algorithms/ai/ai_math/KNN.html">
            
                    
                    K近邻
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.2.5" data-path="../../algorithms/ai/ai_math/DecisionTrees.html">
            
                <a href="../../algorithms/ai/ai_math/DecisionTrees.html">
            
                    
                    决策树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.2.6" data-path="../../algorithms/ai/ai_math/RandomForest.html">
            
                <a href="../../algorithms/ai/ai_math/RandomForest.html">
            
                    
                    随机森林
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.2.7" data-path="../../algorithms/ai/ai_math/AdaBoost.html">
            
                <a href="../../algorithms/ai/ai_math/AdaBoost.html">
            
                    
                    AdaBoost
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.2.8" data-path="../../algorithms/ai/ai_math/GBDT.html">
            
                <a href="../../algorithms/ai/ai_math/GBDT.html">
            
                    
                    梯度提升树
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.2.9" data-path="../../algorithms/ai/ai_math/XGBoost.html">
            
                <a href="../../algorithms/ai/ai_math/XGBoost.html">
            
                    
                    XGBoost
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.2.3" data-path="../../algorithms/ai/Machine_Learning_for_Humans/">
            
                <a href="../../algorithms/ai/Machine_Learning_for_Humans/">
            
                    
                    写给人类的机器学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.2.3.1" data-path="../../algorithms/ai/Machine_Learning_for_Humans/READ_ME.html">
            
                <a href="../../algorithms/ai/Machine_Learning_for_Humans/READ_ME.html">
            
                    
                    写给人类的机器学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.3.2" data-path="../../algorithms/ai/Machine_Learning_for_Humans/1.html">
            
                <a href="../../algorithms/ai/Machine_Learning_for_Humans/1.html">
            
                    
                    一、为什么机器学习重要
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.3.3" data-path="../../algorithms/ai/Machine_Learning_for_Humans/2.1.html">
            
                <a href="../../algorithms/ai/Machine_Learning_for_Humans/2.1.html">
            
                    
                    2.1 监督学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.3.4" data-path="../../algorithms/ai/Machine_Learning_for_Humans/2.2.html">
            
                <a href="../../algorithms/ai/Machine_Learning_for_Humans/2.2.html">
            
                    
                    2.2 监督学习 II
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.3.5" data-path="../../algorithms/ai/Machine_Learning_for_Humans/2.3.html">
            
                <a href="../../algorithms/ai/Machine_Learning_for_Humans/2.3.html">
            
                    
                    2.3 监督学习 III
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.3.6" data-path="../../algorithms/ai/Machine_Learning_for_Humans/3.html">
            
                <a href="../../algorithms/ai/Machine_Learning_for_Humans/3.html">
            
                    
                    三、无监督学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.3.7" data-path="../../algorithms/ai/Machine_Learning_for_Humans/4.html">
            
                <a href="../../algorithms/ai/Machine_Learning_for_Humans/4.html">
            
                    
                    四、神经网络和深度学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.3.8" data-path="../../algorithms/ai/Machine_Learning_for_Humans/5.html">
            
                <a href="../../algorithms/ai/Machine_Learning_for_Humans/5.html">
            
                    
                    五、强化学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2.3.9" data-path="../../algorithms/ai/Machine_Learning_for_Humans/6.html">
            
                <a href="../../algorithms/ai/Machine_Learning_for_Humans/6.html">
            
                    
                    六、最好的机器学习资源
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="../../algorithms/other_algo/">
            
                <a href="../../algorithms/other_algo/">
            
                    
                    算法杂谈
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.3.1" data-path="../../algorithms/other_algo/Sorting.html">
            
                <a href="../../algorithms/other_algo/Sorting.html">
            
                    
                    10 大排序算法总结
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3.2" data-path="../../algorithms/other_algo/Searching.html">
            
                <a href="../../algorithms/other_algo/Searching.html">
            
                    
                    七大查找算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3.3" data-path="../../algorithms/other_algo/Graph_traversal_and_graph_connectivity.html">
            
                <a href="../../algorithms/other_algo/Graph_traversal_and_graph_connectivity.html">
            
                    
                    图的遍历和图的连通性
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="../../algorithms/think_complexity/">
            
                <a href="../../algorithms/think_complexity/">
            
                    
                    复杂性思维
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.4.1" data-path="../../algorithms/think_complexity/1.html">
            
                <a href="../../algorithms/think_complexity/1.html">
            
                    
                    一、复杂性科学
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.2" data-path="../../algorithms/think_complexity/2.html">
            
                <a href="../../algorithms/think_complexity/2.html">
            
                    
                    二、图
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.3" data-path="../../algorithms/think_complexity/3.html">
            
                <a href="../../algorithms/think_complexity/3.html">
            
                    
                    三、小世界图
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.4" data-path="../../algorithms/think_complexity/4.html">
            
                <a href="../../algorithms/think_complexity/4.html">
            
                    
                    四、无标度网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.5" data-path="../../algorithms/think_complexity/5.html">
            
                <a href="../../algorithms/think_complexity/5.html">
            
                    
                    五、细胞自动机
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.6" data-path="../../algorithms/think_complexity/6.html">
            
                <a href="../../algorithms/think_complexity/6.html">
            
                    
                    六、生命游戏
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.7" data-path="../../algorithms/think_complexity/7.html">
            
                <a href="../../algorithms/think_complexity/7.html">
            
                    
                    七、物理建模
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.8" data-path="../../algorithms/think_complexity/8.html">
            
                <a href="../../algorithms/think_complexity/8.html">
            
                    
                    八、自组织临界
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.9" data-path="../../algorithms/think_complexity/9.html">
            
                <a href="../../algorithms/think_complexity/9.html">
            
                    
                    九、基于智能体的模型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.10" data-path="../../algorithms/think_complexity/10.html">
            
                <a href="../../algorithms/think_complexity/10.html">
            
                    
                    十、兽群、鸟群和交通堵塞
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.11" data-path="../../algorithms/think_complexity/11.html">
            
                <a href="../../algorithms/think_complexity/11.html">
            
                    
                    十一、进化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.12" data-path="../../algorithms/think_complexity/12.html">
            
                <a href="../../algorithms/think_complexity/12.html">
            
                    
                    十二、合作进化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.13" data-path="../../algorithms/think_complexity/a.html">
            
                <a href="../../algorithms/think_complexity/a.html">
            
                    
                    附录 A、算法分析
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4.14" data-path="../../algorithms/think_complexity/b.html">
            
                <a href="../../algorithms/think_complexity/b.html">
            
                    
                    附录 B、阅读列表
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" data-path="../../ap/">
            
                <a href="../../ap/">
            
                    
                    AP课程
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../../ap/csa.html">
            
                <a href="../../ap/csa.html">
            
                    
                    AP 计算机A CSA
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1.1" data-path="../../ap/csa/AP_CSA_Profile.html">
            
                <a href="../../ap/csa/AP_CSA_Profile.html">
            
                    
                    CSA 课程简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.1.2" data-path="../../ap/csa/AP_Reference.html">
            
                <a href="../../ap/csa/AP_Reference.html">
            
                    
                    CSA AP_Reference
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.1.3" data-path="../../ap/csa/Java_Beginning.html">
            
                <a href="../../ap/csa/Java_Beginning.html">
            
                    
                    CSA Java_Beginning
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.1.4" data-path="../../ap/csa/Java_Array_and_ArrayList.html">
            
                <a href="../../ap/csa/Java_Array_and_ArrayList.html">
            
                    
                    CSA Java_Array_and_ArrayList
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.1.5" data-path="../../ap/csa/Java_Algorithm_Basics.html">
            
                <a href="../../ap/csa/Java_Algorithm_Basics.html">
            
                    
                    CSA Java_Algorithm_Basics
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.1.6" data-path="../../ap/csa/Java_Object_oriented_Programming.html">
            
                <a href="../../ap/csa/Java_Object_oriented_Programming.html">
            
                    
                    CSA Java_Object_oriented_Programming
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.1.7" data-path="../../ap/csa/other.html">
            
                <a href="../../ap/csa/other.html">
            
                    
                    CSA 杂项
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.1.8" data-path="../../ap/csa/History_Questions.html">
            
                <a href="../../ap/csa/History_Questions.html">
            
                    
                    CSA 历史真题
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../../ap/calculus.html">
            
                <a href="../../ap/calculus.html">
            
                    
                    AP 微积分 calculus
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.2.1" data-path="../../ap/calculus/calculus_review.html">
            
                <a href="../../ap/calculus/calculus_review.html">
            
                    
                    calculus review
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2.2" data-path="../../ap/calculus/CalculusOne.html">
            
                <a href="../../ap/calculus/CalculusOne.html">
            
                    
                    CalculusOne
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2.3" data-path="../../ap/calculus/CalculusOne2.html">
            
                <a href="../../ap/calculus/CalculusOne2.html">
            
                    
                    CalculusOne2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2.4" data-path="../../ap/calculus/CalculusOne_part2.html">
            
                <a href="../../ap/calculus/CalculusOne_part2.html">
            
                    
                    CalculusOne_part2
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" data-path="../">
            
                <a href="../">
            
                    
                    数学知识
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../Thomas_Calculus/Thomas_Calculus.html">
            
                <a href="../Thomas_Calculus/Thomas_Calculus.html">
            
                    
                    Thomas Calculus
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2" data-path="../calculus.html">
            
                <a href="../calculus.html">
            
                    
                    calculus
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.2.1" data-path="../../ap/calculus/calculus_review.html">
            
                <a href="../../ap/calculus/calculus_review.html">
            
                    
                    calculus review
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2.2" data-path="../../ap/calculus/CalculusOne.html">
            
                <a href="../../ap/calculus/CalculusOne.html">
            
                    
                    CalculusOne
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2.3" data-path="../../ap/calculus/CalculusOne2.html">
            
                <a href="../../ap/calculus/CalculusOne2.html">
            
                    
                    CalculusOne2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2.4" data-path="../../ap/calculus/CalculusOne_part2.html">
            
                <a href="../../ap/calculus/CalculusOne_part2.html">
            
                    
                    CalculusOne_part2
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2.5" data-path="../Thomas_Calculus/Thomas_Calculus.html">
            
                <a href="../Thomas_Calculus/Thomas_Calculus.html">
            
                    
                    Thomas Calculus
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2.6" data-path="../partial_derivative/partial_derivative.html">
            
                <a href="../partial_derivative/partial_derivative.html">
            
                    
                    partial_derivative
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8.3" data-path="../probability_theory.html">
            
                <a href="../probability_theory.html">
            
                    
                    probability theory
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.3.1" data-path="../probability_theory/ch01.html">
            
                <a href="../probability_theory/ch01.html">
            
                    
                    概率论
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3.2" data-path="../probability_theory/ch02.html">
            
                <a href="../probability_theory/ch02.html">
            
                    
                    离散机率分布
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3.3" data-path="../probability_theory/ch03.html">
            
                <a href="../probability_theory/ch03.html">
            
                    
                    连续机率分布
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3.4" data-path="../probability_theory/ch04.html">
            
                <a href="../probability_theory/ch04.html">
            
                    
                    期望值 条件概率 失忆性
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3.5" data-path="../probability_theory/ch05.html">
            
                <a href="../probability_theory/ch05.html">
            
                    
                    联合概率 边际概率 双变数期望值
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3.6" data-path="../probability_theory/ch06.html">
            
                <a href="../probability_theory/ch06.html">
            
                    
                    多个随机变量之和的概率分布
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.3.7" data-path="../probability_theory/ch07.html">
            
                <a href="../probability_theory/ch07.html">
            
                    
                    随机数
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8.4" data-path="../Discrete_Mathematics_Explained_in_Detail-master.html">
            
                <a href="../Discrete_Mathematics_Explained_in_Detail-master.html">
            
                    
                    Discrete_Mathematics_Explained_in_Detail-master
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.4.1" data-path="../Discrete_Mathematics_Explained_in_Detail-master/CH01_Logic_and_Proofs.html">
            
                <a href="../Discrete_Mathematics_Explained_in_Detail-master/CH01_Logic_and_Proofs.html">
            
                    
                    CH01_Logic_and_Proofs
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.4.2" data-path="../Discrete_Mathematics_Explained_in_Detail-master/CH02_Basic_Structures.html">
            
                <a href="../Discrete_Mathematics_Explained_in_Detail-master/CH02_Basic_Structures.html">
            
                    
                    CH02_Basic_Structures
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.4.3" data-path="../Discrete_Mathematics_Explained_in_Detail-master/CH03_Algorithms.html">
            
                <a href="../Discrete_Mathematics_Explained_in_Detail-master/CH03_Algorithms.html">
            
                    
                    CH03_Algorithms
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.4.4" data-path="../Discrete_Mathematics_Explained_in_Detail-master/CH05_Induction_and_Recursion.html">
            
                <a href="../Discrete_Mathematics_Explained_in_Detail-master/CH05_Induction_and_Recursion.html">
            
                    
                    CH05_Induction_and_Recursion
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.4.5" data-path="../Discrete_Mathematics_Explained_in_Detail-master/CH06_Counting.html">
            
                <a href="../Discrete_Mathematics_Explained_in_Detail-master/CH06_Counting.html">
            
                    
                    CH06_Counting
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.4.6" data-path="../Discrete_Mathematics_Explained_in_Detail-master/CH08_Advanced_Counting_Techniques.html">
            
                <a href="../Discrete_Mathematics_Explained_in_Detail-master/CH08_Advanced_Counting_Techniques.html">
            
                    
                    CH08_Advanced_Counting_Techniques
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8.5" data-path="./">
            
                <a href="./">
            
                    
                    计算与推断思维
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.5.1" data-path="READ_ME.html">
            
                <a href="READ_ME.html">
            
                    
                    计算与推断思维
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.2" data-path="1.html">
            
                <a href="1.html">
            
                    
                    一、数据科学
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.3" data-path="2.html">
            
                <a href="2.html">
            
                    
                    二、因果和实验
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.4" data-path="3.html">
            
                <a href="3.html">
            
                    
                    三、Python 编程
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.5" data-path="4.html">
            
                <a href="4.html">
            
                    
                    四、数据类型
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.6" data-path="5.html">
            
                <a href="5.html">
            
                    
                    五、表格
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.7" data-path="6.html">
            
                <a href="6.html">
            
                    
                    六、可视化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.8" data-path="7.html">
            
                <a href="7.html">
            
                    
                    七、函数和表格
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.9" data-path="8.html">
            
                <a href="8.html">
            
                    
                    八、随机性
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.10" data-path="9.html">
            
                <a href="9.html">
            
                    
                    九、经验分布
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.11" data-path="10.html">
            
                <a href="10.html">
            
                    
                    十、假设检验
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.12" data-path="11.html">
            
                <a href="11.html">
            
                    
                    十一、估计
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.13" data-path="12.html">
            
                <a href="12.html">
            
                    
                    十二、为什么均值重要
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.8.5.14" data-path="13.html">
            
                <a href="13.html">
            
                    
                    十三、预测
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.15" data-path="14.html">
            
                <a href="14.html">
            
                    
                    十四、回归的推断
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.16" data-path="15.html">
            
                <a href="15.html">
            
                    
                    十五、分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.17" data-path="16.html">
            
                <a href="16.html">
            
                    
                    十六、比较两个样本
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.5.18" data-path="17.html">
            
                <a href="17.html">
            
                    
                    十七、更新预测
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" data-path="../../tool/">
            
                <a href="../../tool/">
            
                    
                    工具集合
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.9.1" data-path="../../tool/browser.html">
            
                <a href="../../tool/browser.html">
            
                    
                    浏览器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.2" data-path="../../tool/chrome.html">
            
                <a href="../../tool/chrome.html">
            
                    
                    Chrome
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.3" data-path="../../tool/git.html">
            
                <a href="../../tool/git.html">
            
                    
                    Git
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.4" data-path="../../tool/ssh.html">
            
                <a href="../../tool/ssh.html">
            
                    
                    SSH
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.5" data-path="../../tool/charles.html">
            
                <a href="../../tool/charles.html">
            
                    
                    Charles
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.6" data-path="../../tool/npm.html">
            
                <a href="../../tool/npm.html">
            
                    
                    Npm
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.7" data-path="../../tool/selfnpm.html">
            
                <a href="../../tool/selfnpm.html">
            
                    
                    Npm 私服
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.8" data-path="../../tool/sublime.html">
            
                <a href="../../tool/sublime.html">
            
                    
                    Sublime
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.9.9" data-path="../../tool/docsify.html">
            
                <a href="../../tool/docsify.html">
            
                    
                    docsify
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.10" data-path="../../advance/">
            
                <a href="../../advance/">
            
                    
                    进阶知识
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.10.1" data-path="../../advance/structure.html">
            
                <a href="../../advance/structure.html">
            
                    
                    数据结构与算法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.2" data-path="../../advance/test.html">
            
                <a href="../../advance/test.html">
            
                    
                    测试
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.3" data-path="../../advance/jest.html">
            
                <a href="../../advance/jest.html">
            
                    
                    Jest
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.4" data-path="../../advance/xss.html">
            
                <a href="../../advance/xss.html">
            
                    
                    XSS
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.5" data-path="../../advance/electron.html">
            
                <a href="../../advance/electron.html">
            
                    
                    Electron
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.6" data-path="../../advance/performance.html">
            
                <a href="../../advance/performance.html">
            
                    
                    性能优化
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.7" data-path="../../advance/watch.html">
            
                <a href="../../advance/watch.html">
            
                    
                    监控
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.8" data-path="../../advance/node.html">
            
                <a href="../../advance/node.html">
            
                    
                    Node
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.9" data-path="../../advance/ab.html">
            
                <a href="../../advance/ab.html">
            
                    
                    Ab 压测
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.10" data-path="../../advance/nginx.html">
            
                <a href="../../advance/nginx.html">
            
                    
                    Nginx
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.11" data-path="../../advance/linux.html">
            
                <a href="../../advance/linux.html">
            
                    
                    Linux
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.12" data-path="../../advance/ssh.html">
            
                <a href="../../advance/ssh.html">
            
                    
                    SSH
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.13" data-path="../../advance/docker.html">
            
                <a href="../../advance/docker.html">
            
                    
                    Docker
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.14" data-path="../../advance/crontab.html">
            
                <a href="../../advance/crontab.html">
            
                    
                    crontab 定时任务
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.10.15" data-path="../../advance/vim.html">
            
                <a href="../../advance/vim.html">
            
                    
                    Vim
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.11" data-path="../../docs/">
            
                <a href="../../docs/">
            
                    
                    资料下载
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.11.1" data-path="../../docs/coding-download.html">
            
                <a href="../../docs/coding-download.html">
            
                    
                    编程资料
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.2" data-path="../../docs/student-download.html">
            
                <a href="../../docs/student-download.html">
            
                    
                    学习资料
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.11.3" data-path="../../docs/other-download.html">
            
                <a href="../../docs/other-download.html">
            
                    
                    杂学资料
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.12" data-path="../../about/">
            
                <a href="../../about/">
            
                    
                    友情链接
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.12.1" data-path="../../about/blog.html">
            
                <a href="../../about/blog.html">
            
                    
                    博客链接
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.2" data-path="../../about/tool.html">
            
                <a href="../../about/tool.html">
            
                    
                    工具链接
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.12.3" data-path="../../about/version.html">
            
                <a href="../../about/version.html">
            
                    
                    更新信息
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://github.com/honkit/honkit" target="blank" class="gitbook-link">
            Published with HonKit
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="../.." >十三、预测</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
                                <section class="normal markdown-section">
                                
                                <h1 id="十三、预测">十三、预测</h1>
<blockquote>
<p>原文：<a href="https://github.com/data-8/textbook/tree/gh-pages/chapters/13" target="_blank">Prediction</a></p>
<p>译者：<a href="https://github.com/wizardforcel" target="_blank">飞龙</a></p>
<p>协议：<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a></p>
<p>自豪地采用<a href="https://translate.google.cn/" target="_blank">谷歌翻译</a></p>
</blockquote>
<p>数据科学的一个重要方面，是发现数据可以告诉我们什么未来的事情。气候和污染的数据说了几十年内温度的什么事情？根据一个人的互联网个人信息，哪些网站可能会让他感兴趣？病人的病史如何用来判断他或她对治疗的反应？</p>
<p>为了回答这样的问题，数据科学家已经开发出了预测的方法。在本章中，我们将研究一种最常用的方法，基于一个变量的值来预测另一个变量。</p>
<p>方法的基础由弗朗西斯·高尔顿爵士（Sir Francis Galton）奠定。我们在 7.1 节看到，高尔顿研究了身体特征是如何从一代传到下一代的。他最著名的工作之一，是根据父母的高度预测子女的身高。我们已经研究了高尔顿为此收集的数据集。<code>heights</code>表包含了 934 个成年子女的双亲身高和子女身高（全部以英寸为单位）。</p>
<pre><code class="lang-py"><span class="hljs-comment"># Galton's data on heights of parents and their adult children</span>
galton = Table.read_table(<span class="hljs-string">'galton.csv'</span>)
heights = Table().with_columns(
    <span class="hljs-string">'MidParent'</span>, galton.column(<span class="hljs-string">'midparentHeight'</span>),
    <span class="hljs-string">'Child'</span>, galton.column(<span class="hljs-string">'childHeight'</span>)
    )
heights
</code></pre>
<table>
<thead>
<tr>
<th>MidParent</th>
<th>Child</th>
</tr>
</thead>
<tbody>
<tr>
<td>75.43</td>
<td>73.2</td>
</tr>
<tr>
<td>75.43</td>
<td>69.2</td>
</tr>
<tr>
<td>75.43</td>
<td>69</td>
</tr>
<tr>
<td>75.43</td>
<td>69</td>
</tr>
<tr>
<td>73.66</td>
<td>73.5</td>
</tr>
<tr>
<td>73.66</td>
<td>72.5</td>
</tr>
<tr>
<td>73.66</td>
<td>65.5</td>
</tr>
<tr>
<td>73.66</td>
<td>65.5</td>
</tr>
<tr>
<td>72.06</td>
<td>71</td>
</tr>
<tr>
<td>72.06</td>
<td>68</td>
</tr>
</tbody>
</table>
<p>（省略了 924 行）</p>
<pre><code class="lang-py">heights.scatter(<span class="hljs-string">'MidParent'</span>)
</code></pre>
<p><img src="img/13-1.png" alt=""></img></p>
<p>收集数据的主要原因是能够预测成年子女的身高，他们的父母与数据集中相似。 在注意到两个变量之间的正相关之后，我们在第 7.1 节中做了这些预测。</p>
<p>我们的方法是，基于新人的双亲身高周围的所有点来做预测。 为此，我们编写了一个名为<code>predict_child</code>的函数，该函数以双亲身高作为参数，并返回双亲身高在半英寸之内的，所有子女的平均身高。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict_child</span><span class="hljs-params">(mpht)</span>:</span>
    <span class="hljs-string">"""Return a prediction of the height of a child 
    whose parents have a midparent height of mpht.

    The prediction is the average height of the children 
    whose midparent height is in the range mpht plus or minus 0.5 inches.
    """</span>

    close_points = heights.where(<span class="hljs-string">'MidParent'</span>, are.between(mpht<span class="hljs-number">-0.5</span>, mpht + <span class="hljs-number">0.5</span>))
    <span class="hljs-keyword">return</span> close_points.column(<span class="hljs-string">'Child'</span>).mean()
</code></pre>
<p>我们将函数应用于<code>Midparent</code>列，可视化我们的结果。</p>
<pre><code class="lang-py"><span class="hljs-comment"># Apply predict_child to all the midparent heights</span>

heights_with_predictions = heights.with_column(
    <span class="hljs-string">'Prediction'</span>, heights.apply(predict_child, <span class="hljs-string">'MidParent'</span>)
    )
<span class="hljs-comment"># Draw the original scatter plot along with the predicted values</span>

heights_with_predictions.scatter(<span class="hljs-string">'MidParent'</span>)
</code></pre>
<p><img src="img/13-2.png" alt=""></img></p>
<p>给定双亲身高的预测值，大致位于给定身高处的垂直条形的中心。这种预测方法称为回归。 本章后面我们会看到这个术语的来源。 我们也会看到，我们是否可以避免将“接近”任意定义为“在半英寸之内”。 但是首先我们要开发一个可用于很多环境的方法，来决定一个变量作为另一个变量的预测值有多好。</p>
<h2 id="相关性">相关性</h2>
<p>在本节中，我们将开发一种度量，度量散点图紧密聚集在一条直线上的程度。 形式上，这被称为测量线性关联。</p>
<p><code>hybrid</code>表包含了 1997 年到 2013 年在美国销售的混合动力车的数据。数据来自佛罗里达大学 <a href="http://www.stat.ufl.edu/~winner/" target="_blank">Larry Winner 教授</a>的在线数据档案。这些列为：</p>
<ul>
<li><code>vehicle</code>：车的型号</li>
<li><code>year</code>：出厂年份</li>
<li><code>msrp</code>: 2013 年制造商的建议零售价（美元）</li>
<li><code>acceleration</code>: 加速度（千米每小时每秒）</li>
<li><code>mpg</code>: 燃油效率（英里每加仑）</li>
<li><code>class</code>: 型号的类别</li>
</ul>
<p>（省略了 143 行）</p>
<p>下图是<code>msrp</code>与<code>acceleration</code>的散点图。 这意味着<code>msrp</code>绘制在纵轴上并且<code>acceleration</code>在横轴上。</p>
<pre><code class="lang-py">hybrid.scatter(<span class="hljs-string">'acceleration'</span>, <span class="hljs-string">'msrp'</span>)
</code></pre>
<p><img src="img/13-3.png" alt=""></img></p>
<p>注意正相关。 散点图倾斜向上，表明加速度较大的车辆通常成本更高；相反，价格更高的汽车通常具有更大的加速。</p>
<p><code>msrp</code>与<code>mpg</code>的散点图表明了负相关。 <code>mpg</code>较高的混合动力车往往成本较低。 这似乎令人惊讶，直到你明白了，加速更快的汽车往往燃油效率更低，行驶里程更低。 之前的散点图显示，这些也是价格更高的车型。</p>
<pre><code class="lang-py">hybrid.scatter(<span class="hljs-string">'mpg'</span>, <span class="hljs-string">'msrp'</span>)
</code></pre>
<p><img src="img/13-4.png" alt=""></img></p>
<p>除了负相关，价格与效率的散点图显示了两个变量之间的非线性关系。 这些点似乎围绕在一条曲线周围，而不是一条直线。</p>
<p>但是，如果我们只将数据限制在 SUV 类别中，价格和效率之间仍然负相关的，但是这种关系似乎更为线性。 SUV 价格与加速度之间的关系也呈线性趋势，但是斜率是正的。</p>
<pre><code class="lang-py">suv = hybrid.where(<span class="hljs-string">'class'</span>, <span class="hljs-string">'SUV'</span>)
suv.scatter(<span class="hljs-string">'mpg'</span>, <span class="hljs-string">'msrp'</span>)
</code></pre>
<p><img src="img/13-5.png" alt=""></img></p>
<pre><code class="lang-py">suv.scatter(<span class="hljs-string">'acceleration'</span>, <span class="hljs-string">'msrp'</span>)
</code></pre>
<p><img src="img/13-6.png" alt=""></img></p>
<p>你会注意到，即使不关注变量被测量的单位，我们也可以从散点图的大体方向和形状中得到有用的信息。</p>
<p>事实上，我们可以将所有的变量绘制成标准单位，并且绘图看起来是一样的。 这给了我们一个方法，来比较两个散点图中的线性程度。</p>
<p>回想一下，在前面的章节中，我们定义了<code>standard_units</code>函数来将数值数组转换为标准单位。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">standard_units</span><span class="hljs-params">(any_numbers)</span>:</span>
    <span class="hljs-string">"Convert any array of numbers to standard units."</span>
    <span class="hljs-keyword">return</span> (any_numbers - np.mean(any_numbers))/np.std(any_numbers)
</code></pre>
<p>我们可以使用这个函数重新绘制 SUV 的两个散点图，所有变量都以标准单位测量。</p>
<pre><code class="lang-py">Table().with_columns(
    <span class="hljs-string">'mpg (standard units)'</span>,  standard_units(suv.column(<span class="hljs-string">'mpg'</span>)), 
    <span class="hljs-string">'msrp (standard units)'</span>, standard_units(suv.column(<span class="hljs-string">'msrp'</span>))
).scatter(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)
plots.xlim(<span class="hljs-number">-3</span>, <span class="hljs-number">3</span>)
plots.ylim(<span class="hljs-number">-3</span>, <span class="hljs-number">3</span>);
</code></pre>
<p><img src="img/13-7.png" alt=""></img></p>
<pre><code class="lang-py">Table().with_columns(
    <span class="hljs-string">'acceleration (standard units)'</span>, standard_units(suv.column(<span class="hljs-string">'acceleration'</span>)), 
    <span class="hljs-string">'msrp (standard units)'</span>,         standard_units(suv.column(<span class="hljs-string">'msrp'</span>))
).scatter(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)
plots.xlim(<span class="hljs-number">-3</span>, <span class="hljs-number">3</span>)
plots.ylim(<span class="hljs-number">-3</span>, <span class="hljs-number">3</span>);
</code></pre>
<p><img src="img/13-8.png" alt=""></img></p>
<p>我们在这些数字中看到的关联与我们之前看到的一样。 另外，由于现在两张散点图的刻度完全相同，我们可以看到，第二张图中的线性关系比第一张图中的线性关系更加模糊。</p>
<p>我们现在将定义一个度量，使用标准单位来量化我们看到的这种关联。</p>
<h3 id="相关系数">相关系数</h3>
<p>相关系数测量两个变量之间线性关系的强度。 在图形上，它测量散点图聚集在一条直线上的程度。</p>
<p>相关系数这个术语不容易表述，所以它通常缩写为相关性并用<code>r</code>表示。</p>
<p>以下是一些关于<code>r</code>的数学事实，我们将通过模拟观察。</p>
<ul>
<li>相关系数<code>r</code>是介于<code>-1</code>和<code>1</code>之间的数字。</li>
<li><code>r</code>度量了散点图围绕一条直线聚集的程度。</li>
<li>如果散点图是完美的向上倾斜的直线，<code>r = 1</code>，如果散点图是完美的向下倾斜的直线，<code>r = -1</code>。</li>
</ul>
<p>函数<code>r_scatter</code>接受<code>r</code>值作为参数，模拟相关性非常接近<code>r</code>的散点图。 由于模拟中的随机性，相关性不会完全等于<code>r</code>。</p>
<p>调用<code>r_scatter</code>几次，以<code>r</code>的不同值作为参数，并查看散点图如何变化。</p>
<p>当<code>r = 1</code>时，散点图是完全线性的，向上倾斜。 当<code>r = -1</code>时，散点图是完全线性的，向下倾斜。 当<code>r = 0</code>时，散点图是围绕水平轴的不定形云，并且变量据说是不相关的。</p>
<pre><code class="lang-py">r_scatter(<span class="hljs-number">0.9</span>)
</code></pre>
<p><img src="img/13-9.png" alt=""></img></p>
<pre><code class="lang-py">r_scatter(<span class="hljs-number">0.25</span>)
</code></pre>
<p><img src="img/13-10.png" alt=""></img></p>
<pre><code class="lang-py">r_scatter(<span class="hljs-number">0</span>)
</code></pre>
<p><img src="img/13-11.png" alt=""></img></p>
<pre><code class="lang-py">r_scatter(<span class="hljs-number">-0.55</span>)
</code></pre>
<p><img src="img/13-12.png" alt=""></img></p>
<h3 id="计算r">计算<code>r</code></h3>
<p>目前为止，<code>r</code>的公式还不清楚。 它拥有超出本课程范围的数学基础。 然而，你将会看到，这个计算很简单，可以帮助我们理解<code>r</code>的几个属性。</p>
<p><code>r</code>的公式：</p>
<p><code>r</code>是两个变量的乘积的均值，这两个变量都以标准单位来衡量。</p>
<p>以下是计算中的步骤。 我们将把这些步骤应用于<code>x</code>和<code>y</code>值的简单表格。</p>
<pre><code class="lang-py">x = np.arange(<span class="hljs-number">1</span>, <span class="hljs-number">7</span>, <span class="hljs-number">1</span>)
y = make_array(<span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">1</span>, <span class="hljs-number">5</span>, <span class="hljs-number">2</span>, <span class="hljs-number">7</span>)
t = Table().with_columns(
        <span class="hljs-string">'x'</span>, x,
        <span class="hljs-string">'y'</span>, y
    )
t
</code></pre>
<table>
<thead>
<tr>
<th>x</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
</tr>
<tr>
<td>4</td>
<td>5</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
</tr>
<tr>
<td>6</td>
<td>7</td>
</tr>
</tbody>
</table>
<p>根据散点图，我们预计<code>r</code>将是正值，但不等于 1。</p>
<pre><code class="lang-py">t.scatter(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, s=<span class="hljs-number">30</span>, color=<span class="hljs-string">'red'</span>)
</code></pre>
<p><img src="img/13-13.png" alt=""></img></p>
<p>第一步：将每个变量转换为标准单位。</p>
<pre><code class="lang-py">t_su = t.with_columns(
        <span class="hljs-string">'x (standard units)'</span>, standard_units(x),
        <span class="hljs-string">'y (standard units)'</span>, standard_units(y)
    )
t_su
</code></pre>
<table>
<thead>
<tr>
<th>x</th>
<th>y</th>
<th>x (standard units)</th>
<th>y (standard units)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2</td>
<td>-1.46385</td>
<td>-0.648886</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>-0.87831</td>
<td>-0.162221</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>-0.29277</td>
<td>-1.13555</td>
</tr>
<tr>
<td>4</td>
<td>5</td>
<td>0.29277</td>
<td>0.811107</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
<td>0.87831</td>
<td>-0.648886</td>
</tr>
<tr>
<td>6</td>
<td>7</td>
<td>1.46385</td>
<td>1.78444</td>
</tr>
</tbody>
</table>
<p>第二步：将每一对标准单位相乘</p>
<pre><code class="lang-py">t_product = t_su.with_column(<span class="hljs-string">'product of standard units'</span>, t_su.column(<span class="hljs-number">2</span>) * t_su.column(<span class="hljs-number">3</span>))
t_product
</code></pre>
<table>
<thead>
<tr>
<th>x</th>
<th>y</th>
<th>x (standard units)</th>
<th>y (standard units)</th>
<th>product of standard units</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2</td>
<td>-1.46385</td>
<td>-0.648886</td>
<td>0.949871</td>
</tr>
<tr>
<td>2</td>
<td>3</td>
<td>-0.87831</td>
<td>-0.162221</td>
<td>0.142481</td>
</tr>
<tr>
<td>3</td>
<td>1</td>
<td>-0.29277</td>
<td>-1.13555</td>
<td>0.332455</td>
</tr>
<tr>
<td>4</td>
<td>5</td>
<td>0.29277</td>
<td>0.811107</td>
<td>0.237468</td>
</tr>
<tr>
<td>5</td>
<td>2</td>
<td>0.87831</td>
<td>-0.648886</td>
<td>-0.569923</td>
</tr>
<tr>
<td>6</td>
<td>7</td>
<td>1.46385</td>
<td>1.78444</td>
<td>2.61215</td>
</tr>
</tbody>
</table>
<p>第三步：<code>r</code>是第二步计算的乘积的均值。</p>
<pre><code class="lang-py"><span class="hljs-comment"># r is the average of the products of standard units</span>

r = np.mean(t_product.column(<span class="hljs-number">4</span>))
r
<span class="hljs-number">0.61741639718977093</span>
</code></pre>
<p>正如我们的预期，<code>r</code>是个不等于的正值。</p>
<h3 id="r的性质"><code>r</code>的性质</h3>
<p>计算结果表明：</p>
<p><code>r</code>是一个纯数字。 它没有单位。 这是因为<code>r</code>基于标准单位。
<code>r</code>不受任何轴上单位的影响。 这也是因为<code>r</code>基于标准单位。
<code>r</code>不受轴的交换的影响。 在代数上，这是因为标准单位的乘积不依赖于哪个变量被称为<code>x</code>和<code>y</code>。 在几何上，轴的切换关于<code>y = x</code>直线翻转了散点图，但不会改变群聚度和关联的符号。</p>
<pre><code class="lang-py">t.scatter(<span class="hljs-string">'y'</span>, <span class="hljs-string">'x'</span>, s=<span class="hljs-number">30</span>, color=<span class="hljs-string">'red'</span>)
</code></pre>
<p><img src="img/13-14.png" alt=""></img></p>
<h3 id="correlation函数"><code>correlation</code>函数</h3>
<p>我们将要重复计算相关性，所以定义一个函数会有帮助，这个函数通过执行上述所有步骤来计算它。 让我们定义一个函数<code>correlation</code>，它接受一个表格，和两列的标签。该函数返回<code>r</code>，它是标准单位下这些列的值的乘积的平均值。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">correlation</span><span class="hljs-params">(t, x, y)</span>:</span>
    <span class="hljs-keyword">return</span> np.mean(standard_units(t.column(x))*standard_units(t.column(y)))
</code></pre>
<p>让我们在<code>t</code>的<code>x</code>和<code>y</code>列上调用函数。 该函数返回<code>x</code>和<code>y</code>之间的相关性的相同答案，就像直接应用<code>r</code>的公式一样。</p>
<pre><code class="lang-py">correlation(t, <span class="hljs-string">'x'</span>, <span class="hljs-string">'y'</span>)
<span class="hljs-number">0.61741639718977093</span>
</code></pre>
<p>我们注意到，变量被指定的顺序并不重要。</p>
<pre><code class="lang-py">correlation(t, <span class="hljs-string">'y'</span>, <span class="hljs-string">'x'</span>)
<span class="hljs-number">0.61741639718977093</span>
</code></pre>
<p>在<code>suv</code>表的列上调用<code>correlation</code>，可以使我们看到价格和效率之间的相关性，以及价格和加速度之间的相关性。</p>
<pre><code class="lang-py">correlation(suv, <span class="hljs-string">'mpg'</span>, <span class="hljs-string">'msrp'</span>)
<span class="hljs-number">-0.6667143635709919</span>
correlation(suv, <span class="hljs-string">'acceleration'</span>, <span class="hljs-string">'msrp'</span>)
<span class="hljs-number">0.48699799279959155</span>
</code></pre>
<p>这些数值证实了我们的观察：</p>
<p>价格和效率之间存在负相关关系，而价格和加速度之间存在正相关关系。
价格和加速度之间的线性关系（相关性约为 0.5），比价格和效率之间的线性关系稍弱（相关性约为 -0.67）。
相关性是一个简单而强大的概念，但有时会被误用。 在使用<code>r</code>之前，重要的是要知道相关性能做和不能做什么。</p>
<h3 id="相关不是因果">相关不是因果</h3>
<p>相关只衡量关联，并不意味着因果。 尽管学区内的孩子的体重与数学能力之间的相关性可能是正的，但这并不意味着做数学会使孩子更重，或者说增加体重会提高孩子的数学能力。 年龄是一个使人混淆的变量：平均来说，较大的孩子比较小的孩子更重，数学能力更好。</p>
<h3 id="相关性度量线性关联">相关性度量线性关联</h3>
<p>相关性只测量一种关联 - 线性关联。 具有较强非线性关联的变量可能具有非常低的相关性。 这里有一个变量的例子，它具有完美的二次关联<code>y = x ^ 2</code>，但是相关性等于 0。</p>
<pre><code class="lang-py">new_x = np.arange(<span class="hljs-number">-4</span>, <span class="hljs-number">4.1</span>, <span class="hljs-number">0.5</span>)
nonlinear = Table().with_columns(
        <span class="hljs-string">'x'</span>, new_x,
        <span class="hljs-string">'y'</span>, new_x**<span class="hljs-number">2</span>
    )
nonlinear.scatter(<span class="hljs-string">'x'</span>, <span class="hljs-string">'y'</span>, s=<span class="hljs-number">30</span>, color=<span class="hljs-string">'r'</span>)
</code></pre>
<p><img src="img/13-15.png" alt=""></img></p>
<pre><code class="lang-py">correlation(nonlinear, <span class="hljs-string">'x'</span>, <span class="hljs-string">'y'</span>)
<span class="hljs-number">0.0</span>
</code></pre>
<h3 id="相关性受到离群点影响">相关性受到离群点影响</h3>
<p>离群点可能对相关性有很大的影响。 下面是一个例子，其中通过增加一个离群点，<code>r</code>等于 1 的散点图变成<code>r</code>等于 0 的图。</p>
<pre><code class="lang-py">line = Table().with_columns(
        <span class="hljs-string">'x'</span>, make_array(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>),
        <span class="hljs-string">'y'</span>, make_array(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>)
    )
line.scatter(<span class="hljs-string">'x'</span>, <span class="hljs-string">'y'</span>, s=<span class="hljs-number">30</span>, color=<span class="hljs-string">'r'</span>)
</code></pre>
<p><img src="img/13-16.png" alt=""></img></p>
<pre><code class="lang-py">correlation(line, <span class="hljs-string">'x'</span>, <span class="hljs-string">'y'</span>)
<span class="hljs-number">1.0</span>
outlier = Table().with_columns(
        <span class="hljs-string">'x'</span>, make_array(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">5</span>),
        <span class="hljs-string">'y'</span>, make_array(<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">3</span>, <span class="hljs-number">4</span>, <span class="hljs-number">0</span>)
    )
outlier.scatter(<span class="hljs-string">'x'</span>, <span class="hljs-string">'y'</span>, s=<span class="hljs-number">30</span>, color=<span class="hljs-string">'r'</span>)
</code></pre>
<p><img src="img/13-17.png" alt=""></img></p>
<pre><code class="lang-py">correlation(outlier, <span class="hljs-string">'x'</span>, <span class="hljs-string">'y'</span>)
<span class="hljs-number">0.0</span>
</code></pre>
<h3 id="生态相关性应谨慎解读">生态相关性应谨慎解读</h3>
<p>基于汇总数据的相关性可能会产生误导。 作为一个例子，这里是 2014 年 SAT 批判性阅读和数学成绩的数据。50 个州和华盛顿特区各有一个点。<code>Participation Rate</code>列包含参加考试的高中学生的百分比。 接下来的三列显示了每个州的测试每个部分的平均得分，最后一列是测试总得分的平均值。</p>
<pre><code class="lang-py">sat2014 = Table.read_table(<span class="hljs-string">'sat2014.csv'</span>).sort(<span class="hljs-string">'State'</span>)
sat2014
</code></pre>
<table>
<thead>
<tr>
<th>State</th>
<th>Participation Rate</th>
<th>Critical Reading</th>
<th>Math</th>
<th>Writing</th>
<th>Combined</th>
</tr>
</thead>
<tbody>
<tr>
<td>Alabama</td>
<td>6.7</td>
<td>547</td>
<td>538</td>
<td>532</td>
<td>1617</td>
</tr>
<tr>
<td>Alaska</td>
<td>54.2</td>
<td>507</td>
<td>503</td>
<td>475</td>
<td>1485</td>
</tr>
<tr>
<td>Arizona</td>
<td>36.4</td>
<td>522</td>
<td>525</td>
<td>500</td>
<td>1547</td>
</tr>
<tr>
<td>Arkansas</td>
<td>4.2</td>
<td>573</td>
<td>571</td>
<td>554</td>
<td>1698</td>
</tr>
<tr>
<td>California</td>
<td>60.3</td>
<td>498</td>
<td>510</td>
<td>496</td>
<td>1504</td>
</tr>
<tr>
<td>Colorado</td>
<td>14.3</td>
<td>582</td>
<td>586</td>
<td>567</td>
<td>1735</td>
</tr>
<tr>
<td>Connecticut</td>
<td>88.4</td>
<td>507</td>
<td>510</td>
<td>508</td>
<td>1525</td>
</tr>
<tr>
<td>Delaware</td>
<td>100</td>
<td>456</td>
<td>459</td>
<td>444</td>
<td>1359</td>
</tr>
<tr>
<td>District of Columbia</td>
<td>100</td>
<td>440</td>
<td>438</td>
<td>431</td>
<td>1309</td>
</tr>
<tr>
<td>Florida</td>
<td>72.2</td>
<td>491</td>
<td>485</td>
<td>472</td>
<td>1448</td>
</tr>
</tbody>
</table>
<p>（省略了 41 行）</p>
<p>数学得分与批判性阅读得分的散点图紧密聚集在一条直线上; 相关性接近 0.985。</p>
<pre><code class="lang-py">sat2014.scatter(<span class="hljs-string">'Critical Reading'</span>, <span class="hljs-string">'Math'</span>)
</code></pre>
<p><img src="img/13-18.png" alt=""></img></p>
<pre><code class="lang-py">correlation(sat2014, <span class="hljs-string">'Critical Reading'</span>, <span class="hljs-string">'Math'</span>)
<span class="hljs-number">0.98475584110674341</span>
</code></pre>
<p>这是个非常高的相关性。但重要的是要注意，这并不能反映学生的数学和批判性阅读得分之间的关系强度。</p>
<p>数据由每个州的平均分数组成。但是各州不参加考试 - 而是学生。表中的数据通过将每个州的所有学生聚集为（这个州里面的两个变量的均值处的）单个点而创建。但并不是所有州的学生都会在这个位置，因为学生的表现各不相同。如果你为每个学生绘制一个点，而不是每个州一个点，那么在上图中的每个点周围都会有一圈云状的点。整体画面会更模糊。学生的数学和批判性阅读得分之间的相关性，将低于基于州均值计算的数值。</p>
<p>基于聚合和均值的相关性被称为生态相关性，并且经常用于报告。正如我们刚刚所看到的，他们必须谨慎解读。</p>
<h3 id="严重还是开玩笑？">严重还是开玩笑？</h3>
<p>2012 年，在著名的《新英格兰医学杂志》（New England Journal of Medicine）上发表的一篇论文，研究了一组国家巧克力消费与的诺贝尔奖之间的关系。《科学美国人》（Scientific American）严肃地做出回应，而其他人更加轻松。 欢迎你自行决定！下面的图表应该让你有兴趣去看看。</p>
<p><img src="img/13-19.png" alt=""></img></p>
<h2 id="回归直线">回归直线</h2>
<p>相关系数<code>r</code>并不只是测量散点图中的点聚集在一条直线上的程度。 它也有助于确定点聚集的直线。 在这一节中，我们将追溯高尔顿和皮尔逊发现这条直线的路线。</p>
<p>高尔顿的父母及其成年子女身高的数据显示出线性关系。 当我们基于双亲身高的子女身高的预测大致沿着直线时，就证实了线性。</p>
<pre><code class="lang-py">galton = Table.read_table(<span class="hljs-string">'galton.csv'</span>)

heights = Table().with_columns(
    <span class="hljs-string">'MidParent'</span>, galton.column(<span class="hljs-string">'midparentHeight'</span>),
    <span class="hljs-string">'Child'</span>, galton.column(<span class="hljs-string">'childHeight'</span>)
    )
<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict_child</span><span class="hljs-params">(mpht)</span>:</span>
    <span class="hljs-string">"""Return a prediction of the height of a child 
    whose parents have a midparent height of mpht.

    The prediction is the average height of the children 
    whose midparent height is in the range mpht plus or minus 0.5 inches.
    """</span>

    close_points = heights.where(<span class="hljs-string">'MidParent'</span>, are.between(mpht<span class="hljs-number">-0.5</span>, mpht + <span class="hljs-number">0.5</span>))
    <span class="hljs-keyword">return</span> close_points.column(<span class="hljs-string">'Child'</span>).mean()   
heights_with_predictions = heights.with_column(
    <span class="hljs-string">'Prediction'</span>, heights.apply(predict_child, <span class="hljs-string">'MidParent'</span>)
    )
heights_with_predictions.scatter(<span class="hljs-string">'MidParent'</span>)
</code></pre>
<p><img src="img/13-20.png" alt=""></img></p>
<h3 id="标准单位下的度量">标准单位下的度量</h3>
<p>让我们看看，我们是否能找到一个方法来确定这条线。 首先，注意到线性关联不依赖于度量单位 - 我们也可以用标准单位来衡量这两个变量。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">standard_units</span><span class="hljs-params">(xyz)</span>:</span>
    <span class="hljs-string">"Convert any array of numbers to standard units."</span>
    <span class="hljs-keyword">return</span> (xyz - np.mean(xyz))/np.std(xyz)  
heights_SU = Table().with_columns(
    <span class="hljs-string">'MidParent SU'</span>, standard_units(heights.column(<span class="hljs-string">'MidParent'</span>)),
    <span class="hljs-string">'Child SU'</span>, standard_units(heights.column(<span class="hljs-string">'Child'</span>))
)
heights_SU
</code></pre>
<table>
<thead>
<tr>
<th>MidParent SU</th>
<th>Child SU</th>
</tr>
</thead>
<tbody>
<tr>
<td>3.45465</td>
<td>1.80416</td>
</tr>
<tr>
<td>3.45465</td>
<td>0.686005</td>
</tr>
<tr>
<td>3.45465</td>
<td>0.630097</td>
</tr>
<tr>
<td>3.45465</td>
<td>0.630097</td>
</tr>
<tr>
<td>2.47209</td>
<td>1.88802</td>
</tr>
<tr>
<td>2.47209</td>
<td>1.60848</td>
</tr>
<tr>
<td>2.47209</td>
<td>-0.348285</td>
</tr>
<tr>
<td>2.47209</td>
<td>-0.348285</td>
</tr>
<tr>
<td>1.58389</td>
<td>1.18917</td>
</tr>
<tr>
<td>1.58389</td>
<td>0.350559</td>
</tr>
</tbody>
</table>
<p>（省略了 924 行）</p>
<p>在这个刻度上，我们可以像以前一样精确地计算我们的预测。 但是首先我们必须弄清楚，如何将“接近”的点的旧定义转换为新的刻度上的一个值。 我们曾经说过，如果双亲高度在 0.5 英寸之内，它们就是“接近”的。 由于标准单位以标准差为单位测量距离，所以我们必须计算出，0.5 英寸是多少个双亲身高的标准差。</p>
<p>双亲身高的标准差约为 1.8 英寸。 所以 0.5 英寸约为 0.28 个标准差。</p>
<pre><code class="lang-py">sd_midparent = np.std(heights.column(<span class="hljs-number">0</span>))
sd_midparent
<span class="hljs-number">1.8014050969207571</span>
<span class="hljs-number">0.5</span>/sd_midparent
<span class="hljs-number">0.27756111096536701</span>
</code></pre>
<p>现在我们准备修改我们的预测函数，来预测标准单位。 所有改变的是，我们正在使用标准单位的值的表格，并定义如上所述的“接近”。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">predict_child_su</span><span class="hljs-params">(mpht_su)</span>:</span>
    <span class="hljs-string">"""Return a prediction of the height (in standard units) of a child 
    whose parents have a midparent height of mpht_su in standard units.
    """</span>
    close = <span class="hljs-number">0.5</span>/sd_midparent
    close_points = heights_SU.where(<span class="hljs-string">'MidParent SU'</span>, are.between(mpht_su-close, mpht_su + close))
    <span class="hljs-keyword">return</span> close_points.column(<span class="hljs-string">'Child SU'</span>).mean()   
heights_with_su_predictions = heights_SU.with_column(
    <span class="hljs-string">'Prediction SU'</span>, heights_SU.apply(predict_child_su, <span class="hljs-string">'MidParent SU'</span>)
    )
heights_with_su_predictions.scatter(<span class="hljs-string">'MidParent SU'</span>)
</code></pre>
<p><img src="img/13-21.png" alt=""></img></p>
<p>这个绘图看起来就像在原始刻度上绘图。 只改变了轴上的数字。 这证实了我们可以通过在标准单位下工作，来理解预测过程。</p>
<h3 id="确定标准单位下的直线">确定标准单位下的直线</h3>
<p>高尔顿的散点图形状是个橄榄球 - 就是说，像橄榄球一样大致椭圆形。不是所有的散点图都是橄榄形的，甚至那些线性关联的也不都是。但在这一节中，我们假装我们是高尔顿，只能处理橄榄形的散点图。在下一节中，我们将把我们的分析推广到其他形状的绘图。</p>
<p>这里是一个橄榄形散点图，两个变量以标准单位测量。 45 度线显示为红色。</p>
<p><img src="img/13-22.png" alt=""></img></p>
<p>但是 45 度线不是经过垂直条形的中心的线。你可以看到在下图中，1.5 个标准单位的垂直线显示为黑色。蓝线附近的散点图上的点的高度都大致在 -2 到 3 的范围内。红线太高，无法命中中心。</p>
<p><img src="img/13-23.png" alt=""></img></p>
<p>所以 45 度线不是“均值图”。该线是下面显示的绿线。</p>
<p><img src="img/13-24.png" alt=""></img></p>
<p>两条线都经过原点<code>(0,0)</code>。绿线穿过垂直条形的中心（至少大概），比红色的 45 度线平坦。</p>
<p>45 度线的斜率为 1。所以绿色的“均值图”直线的斜率是正值但小于 1。</p>
<p>这可能是什么值呢？你猜对了 - 这是<code>r</code>。</p>
<h3 id="标准单位下的回归直线">标准单位下的回归直线</h3>
<p>绿色的“均值图”线被称为回归直线，我们将很快解释原因。 但首先，让我们模拟一些<code>r</code>值不同的橄榄形散点图，看看直线是如何变化的。 在每种情况中，绘制红色 45 度线作比较。</p>
<p>执行模拟的函数为<code>regression_line</code>，并以<code>r</code>为参数。</p>
<pre><code class="lang-py">regression_line(<span class="hljs-number">0.95</span>)
</code></pre>
<p><img src="img/13-25.png" alt=""></img></p>
<pre><code class="lang-py">regression_line(<span class="hljs-number">0.6</span>)
</code></pre>
<p><img src="img/13-26.png" alt=""></img></p>
<p>当<code>r</code>接近于 1 时，散点图，45 度线和回归线都非常接近。 但是对于<code>r</code>较低值来说，回归线显然更平坦。</p>
<h3 id="回归效应">回归效应</h3>
<p>就预测而言，这意味着，对于双亲身高为 1.5 个标准单位的家长来说，我们对女子身高的预测要稍低于 1.5 个标准单位。如果双亲高度是 2 个标准单位，我们对子女身高的预测，会比 2 个标准单位少一些。</p>
<p>换句话说，我们预测，子女会比父母更接近均值。</p>
<p>弗朗西斯·高尔顿爵士就不高兴了。他一直希望，特别高的父母会有特别高的子女。然而，数据是清楚的，高尔顿意识到，高个子父母通常拥有并不是特别高的子女。高尔顿沮丧地将这种现象称为“回归平庸”。</p>
<p>高尔顿还注意到，特别矮的父母通常拥有相对于他们这一代高一些的子女。一般来说，一个变量的平均值远远低于另一个变量的平均值。这被称为回归效应。</p>
<h3 id="回归直线的方程">回归直线的方程</h3>
<p>在回归中，我们使用一个变量（我们称<code>x</code>）的值来预测另一个变量的值（我们称之为<code>y</code>）。 当变量<code>x</code>和<code>y</code>以标准单位测量时，基于<code>x</code>预测<code>y</code>的回归线斜率为<code>r</code>并通过原点。 因此，回归线的方程可写为：</p>
<p><img src="img/tex-13-1.gif" alt=""></img></p>
<p>在数据的原始单位下，就变成了：</p>
<p><img src="img/tex-13-2.gif" alt=""></img></p>
<p>原始单位的回归线的斜率和截距可以从上图中导出。</p>
<p><img src="img/tex-13-3.gif" alt=""></img></p>
<p><img src="img/tex-13-4.gif" alt=""></img></p>
<p>下面的三个函数计算相关性，斜率和截距。 它们都有三个参数：表的名称，包含<code>x</code>的列的标签以及包含<code>y</code>的列的标签。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">correlation</span><span class="hljs-params">(t, label_x, label_y)</span>:</span>
    <span class="hljs-keyword">return</span> np.mean(standard_units(t.column(label_x))*standard_units(t.column(label_y)))

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">slope</span><span class="hljs-params">(t, label_x, label_y)</span>:</span>
    r = correlation(t, label_x, label_y)
    <span class="hljs-keyword">return</span> r*np.std(t.column(label_y))/np.std(t.column(label_x))

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">intercept</span><span class="hljs-params">(t, label_x, label_y)</span>:</span>
    <span class="hljs-keyword">return</span> np.mean(t.column(label_y)) - slope(t, label_x, label_y)*np.mean(t.column(label_x))
</code></pre>
<h3 id="回归直线和高尔顿的数据">回归直线和高尔顿的数据</h3>
<p>双亲身高和子女身高之间的相关性是 0.32：</p>
<pre><code class="lang-py">galton_r = correlation(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)
galton_r
<span class="hljs-number">0.32094989606395924</span>
</code></pre>
<p>我们也可以找到回归直线的方程，来基于双亲身高预测子女身高：</p>
<pre><code class="lang-py">galton_slope = slope(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)
galton_intercept = intercept(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)
galton_slope, galton_intercept
(<span class="hljs-number">0.63736089696947895</span>, <span class="hljs-number">22.636240549589751</span>)
</code></pre>
<p>回归直线的方程是：</p>
<p><img src="img/tex-13-5.gif" alt=""></img></p>
<p>这也成为回归方程。回归方程的主要用途是根据<code>x</code>预测<code>y</code>。</p>
<p>例如，对于 70.48 英寸的双亲身高，回归直线预测，子女身高为 67.56 英寸。</p>
<pre><code class="lang-py">galton_slope*<span class="hljs-number">70.48</span> + galton_intercept
<span class="hljs-number">67.557436567998622</span>
</code></pre>
<p>我们最初的预测，通过计算双亲身高接近 70.48 的所有子女的平均身高来完成，这个预测非常接近：67.63 英寸，而回归线的预测是 67.55 英寸。</p>
<pre><code class="lang-py">heights_with_predictions.where(<span class="hljs-string">'MidParent'</span>, are.equal_to(<span class="hljs-number">70.48</span>)).show(<span class="hljs-number">3</span>)
</code></pre>
<table>
<thead>
<tr>
<th>MidParent</th>
<th>Child</th>
<th>Prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td>70.48</td>
<td>74</td>
<td>67.6342</td>
</tr>
<tr>
<td>70.48</td>
<td>70</td>
<td>67.6342</td>
</tr>
<tr>
<td>70.48</td>
<td>68</td>
<td>67.6342</td>
</tr>
</tbody>
</table>
<p>（省略了 5 行）</p>
<p>这里是高尔顿的表格的所有行，我们的原始预测，以及子女身高的回归预测。</p>
<pre><code class="lang-py">heights_with_predictions = heights_with_predictions.with_column(
    <span class="hljs-string">'Regression Prediction'</span>, galton_slope*heights.column(<span class="hljs-string">'MidParent'</span>) + galton_intercept
)
heights_with_predictions
</code></pre>
<table>
<thead>
<tr>
<th>MidParent</th>
<th>Child</th>
<th>Prediction</th>
<th>Regression Prediction</th>
</tr>
</thead>
<tbody>
<tr>
<td>75.43</td>
<td>73.2</td>
<td>70.1</td>
<td>70.7124</td>
</tr>
<tr>
<td>75.43</td>
<td>69.2</td>
<td>70.1</td>
<td>70.7124</td>
</tr>
<tr>
<td>75.43</td>
<td>69</td>
<td>70.1</td>
<td>70.7124</td>
</tr>
<tr>
<td>75.43</td>
<td>69</td>
<td>70.1</td>
<td>70.7124</td>
</tr>
<tr>
<td>73.66</td>
<td>73.5</td>
<td>70.4158</td>
<td>69.5842</td>
</tr>
<tr>
<td>73.66</td>
<td>72.5</td>
<td>70.4158</td>
<td>69.5842</td>
</tr>
<tr>
<td>73.66</td>
<td>65.5</td>
<td>70.4158</td>
<td>69.5842</td>
</tr>
<tr>
<td>73.66</td>
<td>65.5</td>
<td>70.4158</td>
<td>69.5842</td>
</tr>
<tr>
<td>72.06</td>
<td>71</td>
<td>68.5025</td>
<td>68.5645</td>
</tr>
<tr>
<td>72.06</td>
<td>68</td>
<td>68.5025</td>
<td>68.5645</td>
</tr>
</tbody>
</table>
<p>（省略了 924 行）</p>
<pre><code class="lang-py">heights_with_predictions.scatter(<span class="hljs-string">'MidParent'</span>)
</code></pre>
<p><img src="img/13-27.png" alt=""></img></p>
<p>灰色圆点显示回归预测，全部在回归线上。 注意这条线与均值的金色图非常接近。 对于这些数据，回归线很好地逼近垂直条形的中心。</p>
<h3 id="拟合值">拟合值</h3>
<p>所有的预测值都在直线上，被称为“拟合值”。 函数<code>fit</code>使用表名和<code>x</code>和<code>y</code>的标签，并返回一个拟合值数组，散点图中每个点一个。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">fit</span><span class="hljs-params">(table, x, y)</span>:</span>
    <span class="hljs-string">"""Return the height of the regression line at each x value."""</span>
    a = slope(table, x, y)
    b = intercept(table, x, y)
    <span class="hljs-keyword">return</span> a * table.column(x) + b
</code></pre>
<p>下图比上图更轻易看到直线：</p>
<pre><code class="lang-py">heights.with_column(<span class="hljs-string">'Fitted'</span>, fit(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)).scatter(<span class="hljs-string">'MidParent'</span>)
</code></pre>
<p><img src="img/13-28.png" alt=""></img></p>
<p>另一个绘制直线的方式是在表方法<code>scatter</code>中，使用选项<code>fit_line=True</code>。</p>
<pre><code class="lang-py">heights.scatter(<span class="hljs-string">'MidParent'</span>, fit_line=<span class="hljs-keyword">True</span>)
</code></pre>
<p><img src="img/13-29.png" alt=""></img></p>
<h3 id="斜率的测量单位">斜率的测量单位</h3>
<p>斜率是一个比值，值得花点时间来研究它的测量单位。 我们的例子来自熟悉的医院系统中产妇的数据集。 孕期体重与高度的散点图看起来像是一个橄榄球，已经在一场比赛中使用了很多次，但足够接近橄榄球，我们可以让我们的拟合直线穿过它来证明。 在后面的章节中，我们将看到如何使这种证明更正式。</p>
<pre><code class="lang-py">baby = Table.read_table(<span class="hljs-string">'baby.csv'</span>)
baby.scatter(<span class="hljs-string">'Maternal Height'</span>, <span class="hljs-string">'Maternal Pregnancy Weight'</span>, fit_line=<span class="hljs-keyword">True</span>)
</code></pre>
<p><img src="img/13-30.png" alt=""></img></p>
<pre><code class="lang-py">slope(baby, <span class="hljs-string">'Maternal Height'</span>, <span class="hljs-string">'Maternal Pregnancy Weight'</span>)
<span class="hljs-number">3.5728462592750558</span>
</code></pre>
<p>回归线的斜率是 3.57 磅每英寸。 这意味着，对于身高相差 1 英寸的两名女性来说，我们对孕期体重的预测相差 3.57 磅。 对于身高相差 2 英寸的女性，我们预测的孕期体重相差<code>2 * 3.57 ~= 7.14</code>磅。</p>
<p>请注意，散点图中的连续垂直条形相距 1 英寸，因为高度已经舍入到最近的英寸。 另一种考虑斜率的方法是取两个相连的条形（相隔 1 英寸），相当于两组身高相差 1 英寸的女性。 3.57 磅每英寸的斜率意味着，较高组的平均孕期体重比较矮组多大约 3.57 磅。</p>
<h3 id="示例">示例</h3>
<p>假设我们的目标是使用回归，基于巴塞特猎犬的体重来估计它的身高，所用的样本与回归模型看起来一致。 假设观察到的相关性<code>r</code>为 0.5，并且这两个变量的汇总统计量如下表所示：</p>
<table>
<thead>
<tr>
<th></th>
<th>average</th>
<th>SD</th>
</tr>
</thead>
<tbody>
<tr>
<td>height</td>
<td>14 inches</td>
<td>2 inches</td>
</tr>
<tr>
<td>weight</td>
<td>50 pounds</td>
<td>5 pounds</td>
</tr>
</tbody>
</table>
<p>为了计算回归线的方程，我们需要斜率和截距。</p>
<p><img src="img/tex-13-6.gif" alt=""></img></p>
<p><img src="img/tex-13-7.gif" alt=""></img></p>
<p>回归线的方程允许我们，根据给定重量（磅）计算估计高度（英寸）：</p>
<p><img src="img/tex-13-8.gif" alt=""></img></p>
<p>线的斜率衡量随着重量的单位增长的估计高度的增长。 斜率是正值，重要的是要注意，这并不表示我们认为，如果体重增加巴塞特猎狗就会变得更高。 斜率反映了两组狗的平均身高的差异，这两组狗的体重相差 1 磅。 具体来说，考虑一组重量为<code>w</code>磅，以及另一组重量为<code>w + 1</code>磅的狗。 我们估计，第二组的均值高出 0.2 英寸。 对于样本中的所有<code>w</code>值都是如此。</p>
<p>一般来说，回归线的斜率可以解释为随着<code>x</code>单位增长的<code>y</code>平均增长。 请注意，如果斜率为负值，那么对于<code>x</code>的每单位增长，<code>y</code>的平均值会减少。</p>
<h3 id="尾注">尾注</h3>
<p>即使我们没有建立回归方程的数学基础，我们可以看到，当散点图是橄榄形的时候，它会给出相当好的预测。 这是一个令人惊讶的数学事实，无论散点图的形状如何，同一个方程给出所有直线中的“最好”的预测。 这是下一节的主题。</p>
<h2 id="最小二乘法">最小二乘法</h2>
<p>我们已经回溯了高尔顿和皮尔森用于开发回归线方程的步骤，它穿过橄榄形的散点图。但不是所有的散点图都是橄榄形的，甚至不是线性的。每个散点图都有一个“最优”直线吗？如果是这样，我们仍然可以使用上一节中开发的斜率和截距公式，还是需要新的公式？</p>
<p>为了解决这些问题，我们需要一个“最优”的合理定义。回想一下，这条线的目的是预测或估计<code>y</code>的值，在给定<code>x</code>值的情况下。估计通常不是完美的。每个值都由于误差而偏离真正的值。“最优”直线的合理标准是，它在所有直线中总体误差尽可能最小。</p>
<p>在本节中，我们将精确确定这个标准，看看我们能否确定标准下的最优直线。</p>
<p>我们的第一个例子是小说《小女人》数据集，每章都有一行。目标是根据句子数来估计字符数（即字母，空格标点符号等等）。回想一下，我们在本课程的第一堂课中试图实现它。</p>
<pre><code class="lang-py">little_women = Table.read_table(<span class="hljs-string">'little_women.csv'</span>)
little_women = little_women.move_to_start(<span class="hljs-string">'Periods'</span>)
little_women.show(<span class="hljs-number">3</span>)
</code></pre>
<table>
<thead>
<tr>
<th>Periods</th>
<th>Characters</th>
</tr>
</thead>
<tbody>
<tr>
<td>189</td>
<td>21759</td>
</tr>
<tr>
<td>188</td>
<td>22148</td>
</tr>
<tr>
<td>231</td>
<td>20558</td>
</tr>
</tbody>
</table>
<p>（省略了 44 行）</p>
<pre><code class="lang-py">little_women.scatter(<span class="hljs-string">'Periods'</span>, <span class="hljs-string">'Characters'</span>)
</code></pre>
<p><img src="img/13-31.png" alt=""></img></p>
<p>为了探索数据，我们将需要使用上一节定义的函数<code>correlation</code>，<code>slope</code>，<code>intercept</code>和<code>fit</code>。</p>
<pre><code class="lang-py">correlation(little_women, <span class="hljs-string">'Periods'</span>, <span class="hljs-string">'Characters'</span>)
<span class="hljs-number">0.92295768958548163</span>
</code></pre>
<p>散点图明显接近线性，相关性大于 0.92。</p>
<h3 id="估计中的误差">估计中的误差</h3>
<p>下图显示了我们在上一节中开发的散点图和直线。 我们还不知道这是否是所有直线中最优的。 我们首先必须准确表达“最优”的意思。</p>
<pre><code class="lang-py">lw_with_predictions = little_women.with_column(<span class="hljs-string">'Linear Prediction'</span>, fit(little_women, <span class="hljs-string">'Periods'</span>, <span class="hljs-string">'Characters'</span>))
lw_with_predictions.scatter(<span class="hljs-string">'Periods'</span>)
</code></pre>
<p><img src="img/13-32.png" alt=""></img></p>
<p>对应于散点图上的每个点，预测的误差是计算为实际值减去预测值。 它是点与直线之间的垂直距离，如果点在线之下，则为负值。</p>
<pre><code class="lang-py">actual = lw_with_predictions.column(<span class="hljs-string">'Characters'</span>)
predicted = lw_with_predictions.column(<span class="hljs-string">'Linear Prediction'</span>)
errors = actual - predicted
lw_with_predictions.with_column(<span class="hljs-string">'Error'</span>, errors)
</code></pre>
<table>
<thead>
<tr>
<th>Periods</th>
<th>Characters</th>
<th>Linear Prediction</th>
<th>Error</th>
</tr>
</thead>
<tbody>
<tr>
<td>189</td>
<td>21759</td>
<td>21183.6</td>
<td>575.403</td>
</tr>
<tr>
<td>188</td>
<td>22148</td>
<td>21096.6</td>
<td>1051.38</td>
</tr>
<tr>
<td>231</td>
<td>20558</td>
<td>24836.7</td>
<td>-4278.67</td>
</tr>
<tr>
<td>195</td>
<td>25526</td>
<td>21705.5</td>
<td>3820.54</td>
</tr>
<tr>
<td>255</td>
<td>23395</td>
<td>26924.1</td>
<td>-3529.13</td>
</tr>
<tr>
<td>140</td>
<td>14622</td>
<td>16921.7</td>
<td>-2299.68</td>
</tr>
<tr>
<td>131</td>
<td>14431</td>
<td>16138.9</td>
<td>-1707.88</td>
</tr>
<tr>
<td>214</td>
<td>22476</td>
<td>23358</td>
<td>-882.043</td>
</tr>
<tr>
<td>337</td>
<td>33767</td>
<td>34056.3</td>
<td>-289.317</td>
</tr>
<tr>
<td>185</td>
<td>18508</td>
<td>20835.7</td>
<td>-2327.69</td>
</tr>
</tbody>
</table>
<p>（省略了 37 行）</p>
<p>我们可以使用<code>slope</code>和<code>intercept</code>来计算拟合直线的斜率和截距。 下图显示了该直线（浅蓝色）。 对应于四个点的误差以红色显示。 这四个点没什么特别的。 他们只是为了展示的清晰而被选中。 函数<code>lw_errors</code>以斜率和截距（按照该顺序）作为参数，并绘制该图形。</p>
<pre><code class="lang-py">lw_reg_slope = slope(little_women, <span class="hljs-string">'Periods'</span>, <span class="hljs-string">'Characters'</span>)
lw_reg_intercept = intercept(little_women, <span class="hljs-string">'Periods'</span>, <span class="hljs-string">'Characters'</span>)
print(<span class="hljs-string">'Slope of Regression Line:    '</span>, np.round(lw_reg_slope), <span class="hljs-string">'characters per period'</span>)
print(<span class="hljs-string">'Intercept of Regression Line:'</span>, np.round(lw_reg_intercept), <span class="hljs-string">'characters'</span>)
lw_errors(lw_reg_slope, lw_reg_intercept)
Slope of Regression Line:     <span class="hljs-number">87.0</span> characters per period
Intercept of Regression Line: <span class="hljs-number">4745.0</span> characters
</code></pre>
<p><img src="img/13-33.png" alt=""></img></p>
<p>如果我们用不同的线来创建我们的估计，误差将会不同。 下面的图表显示了如果我们使用另一条线进行估算，误差会有多大。 第二张图显示了通过使用完全愚蠢的线获得了较大误差。</p>
<pre><code class="lang-py">lw_errors(<span class="hljs-number">50</span>, <span class="hljs-number">10000</span>)
</code></pre>
<p><img src="img/13-34.png" alt=""></img></p>
<pre><code class="lang-py">lw_errors(<span class="hljs-number">-100</span>, <span class="hljs-number">50000</span>)
</code></pre>
<p><img src="img/13-35.png" alt=""></img></p>
<h3 id="均方根误差（rmse）">均方根误差（RMSE）</h3>
<p>我们现在需要的是误差大小的一个总体衡量。 你会认识到创建它的方法 - 这正是我们开发标准差的方式。</p>
<p>如果你使用任意直线来计算你的估计值，那么你的一些误差可能是正的，而其他的则是负的。 为了避免误差大小在测量时抵消，我们将采用误差平方的均值而不是误差的均值。</p>
<p>估计的均方误差大概是误差的平方有多大，但正如我们前面提到的，它的单位很难解释。 取平方根产生均方根误差（RMSE），与预测变量的单位相同，因此更容易理解。</p>
<h3 id="使-rmse-最小">使 RMSE 最小</h3>
<p>到目前为止，我们的观察可以总结如下。</p>
<ul>
<li>要根据<code>x</code>估算<code>y</code>，可以使用任何你想要的直线。</li>
<li>每个直线都有估计的均方根误差。</li>
<li>“更好”的直线有更小的误差。</li>
</ul>
<p>有没有“最好”的直线？ 也就是说，是否有一条线可以使所有行中的均方根误差最小？</p>
<p>为了回答这个问题，我们首先定义一个函数<code>lw_rmse</code>，通过《小女人》的散点图来计算任意直线的均方根误差。 函数将斜率和截距（按此顺序）作为参数。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lw_rmse</span><span class="hljs-params">(slope, intercept)</span>:</span>
    lw_errors(slope, intercept)
    x = little_women.column(<span class="hljs-string">'Periods'</span>)
    y = little_women.column(<span class="hljs-string">'Characters'</span>)
    fitted = slope * x + intercept
    mse = np.mean((y - fitted) ** <span class="hljs-number">2</span>)
    print(<span class="hljs-string">"Root mean squared error:"</span>, mse ** <span class="hljs-number">0.5</span>)
lw_rmse(<span class="hljs-number">50</span>, <span class="hljs-number">10000</span>)
Root mean squared error: <span class="hljs-number">4322.16783177</span>
</code></pre>
<p><img src="img/13-36.png" alt=""></img></p>
<pre><code class="lang-py">lw_rmse(<span class="hljs-number">-100</span>, <span class="hljs-number">50000</span>)
Root mean squared error: <span class="hljs-number">16710.1198374</span>
</code></pre>
<p><img src="img/13-37.png" alt=""></img></p>
<p>正如预期的那样，不好的直线 RMSE 很大。 但是如果我们选择接近于回归线的斜率和截距，则 RMSE 要小得多。</p>
<pre><code class="lang-py">lw_rmse(<span class="hljs-number">90</span>, <span class="hljs-number">4000</span>)
Root mean squared error: <span class="hljs-number">2715.53910638</span>
</code></pre>
<p><img src="img/13-38.png" alt=""></img></p>
<p>这是对应于回归线的均方根误差。 通过显着的数学事实，没有其他线路能击败这一条。</p>
<p>回归线是所有直线之间的唯一直线，使估计的均方误差最小。</p>
<pre><code class="lang-py">lw_rmse(lw_reg_slope, lw_reg_intercept)
Root mean squared error: <span class="hljs-number">2701.69078531</span>
</code></pre>
<p><img src="img/13-39.png" alt=""></img></p>
<p>这个声明的证明需要超出本课程范围的抽象数学。 另一方面，我们有一个强大的工具 -- Python，它可以轻松执行大量的数值计算。 所以我们可以使用 Python 来确认回归线最小化的均方误差。</p>
<h3 id="数值优化">数值优化</h3>
<p>首先注意，使均方根误差最小的直线，也是使平方误差最小的直线。 平方根对最小值没有任何影响。 所以我们会为自己节省一个计算步骤，并将平均方差 MSE 减到最小。</p>
<p>我们试图根据《小女人》的句子数（<code>x</code>）来预测字符数量（<code>y</code>）。 如果我们使用 <img src="img/tex-13-9.gif" alt=""></img> 直线，它将有一个 MSE，它取决于斜率<code>a</code>和截距<code>b</code>。 函数<code>lw_mse</code>以斜率和截距为参数，并返回相应的 MSE。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">lw_mse</span><span class="hljs-params">(any_slope, any_intercept)</span>:</span>
    x = little_women.column(<span class="hljs-string">'Periods'</span>)
    y = little_women.column(<span class="hljs-string">'Characters'</span>)
    fitted = any_slope*x + any_intercept
    <span class="hljs-keyword">return</span> np.mean((y - fitted) ** <span class="hljs-number">2</span>)
</code></pre>
<p>让我们确认一下，<code>lw_mse</code>得到回归线的 RMSE 的正确答案。 请记住，<code>lw_mse</code>返回均方误差，所以我们必须取平方根来得到 RMSE。</p>
<pre><code class="lang-py">lw_mse(lw_reg_slope, lw_reg_intercept)**<span class="hljs-number">0.5</span>
<span class="hljs-number">2701.690785311856</span>
</code></pre>
<p><img src="img/13-40.png" alt=""></img></p>
<p>它和我们之前使用<code>lw_rmse</code>得到的值相同。</p>
<pre><code class="lang-py">lw_rmse(lw_reg_slope, lw_reg_intercept)
Root mean squared error: <span class="hljs-number">2701.69078531</span>
</code></pre>
<p>你可以确认对于其他的斜率和截距，<code>lw_mse</code>也返回正确的值。 例如，这里是我们之前尝试的，非常不好的直线的 RMSE。</p>
<pre><code class="lang-py">lw_mse(<span class="hljs-number">-100</span>, <span class="hljs-number">50000</span>)**<span class="hljs-number">0.5</span>
<span class="hljs-number">16710.119837353752</span>
</code></pre>
<p>这里是这条直线的 RMSE，它接近回归线。</p>
<pre><code class="lang-py">lw_mse(<span class="hljs-number">90</span>, <span class="hljs-number">4000</span>)**<span class="hljs-number">0.5</span>
<span class="hljs-number">2715.5391063834586</span>
</code></pre>
<p>如果我们尝试不同的值，我们可以通过反复试验找到一个误差较低的斜率和截距，但这需要一段时间。 幸运的是，有一个 Python 函数为我们做了所有的试错。</p>
<p><code>minimize</code>函数可用于寻找函数的参数，函数在这里返回其最小值。 Python 使用类似的试错法，遵循使输出值递减的变化量。</p>
<p><code>minimize</code>的参数是一个函数，它本身接受数值参数并返回一个数值。 例如，函数<code>lw_mse</code>以数值斜率和截距作为参数，并返回相应的 MSE。</p>
<p>调用<code>minimize(lw_mse)</code>返回一个数组，由斜率和截距组成，它们使 MSE 最小。 这些最小值是通过智能试错得出的极好的近似值，而不是基于公式的精确值。</p>
<pre><code class="lang-py">best = minimize(lw_mse)
best
array([   <span class="hljs-number">86.97784117</span>,  <span class="hljs-number">4744.78484535</span>])
</code></pre>
<p>这些值与我们之前使用<code>slope</code>和<code>intercept</code>函数计算的值相同。 由于最小化的不精确性，我们看到较小的偏差，但是这些值本质上是相同的。</p>
<pre><code class="lang-py">print(<span class="hljs-string">"slope from formula:        "</span>, lw_reg_slope)
print(<span class="hljs-string">"slope from minimize:       "</span>, best.item(<span class="hljs-number">0</span>))
print(<span class="hljs-string">"intercept from formula:    "</span>, lw_reg_intercept)
print(<span class="hljs-string">"intercept from minimize:   "</span>, best.item(<span class="hljs-number">1</span>))
slope <span class="hljs-keyword">from</span> formula:         <span class="hljs-number">86.9778412583</span>
slope <span class="hljs-keyword">from</span> minimize:        <span class="hljs-number">86.97784116615884</span>
intercept <span class="hljs-keyword">from</span> formula:     <span class="hljs-number">4744.78479657</span>
intercept <span class="hljs-keyword">from</span> minimize:    <span class="hljs-number">4744.784845352655</span>
</code></pre>
<h3 id="最小二乘直线">最小二乘直线</h3>
<p>因此我们发现，不仅回归线具有最小的均方误差，而且均方误差的最小化也给出了回归线。 回归线是最小化均方误差的唯一直线。</p>
<p>这就是回归线有时被称为“最小二乘直线”的原因。</p>
<h2 id="最小二乘回归">最小二乘回归</h2>
<p>在前面的章节中，我们开发了回归直线的斜率和截距方程，它穿过一个橄榄形的散点图。 事实证明，无论散点图的形状如何，最小二乘直线的斜率和截距都与我们开发的公式相同。</p>
<p>我们在《小女人》的例子中看到了它，但是让我们以散点图显然不是橄榄形的例子来证实它。 对于这些数据，我们再次受惠于佛罗里达大学 Larry Winner 教授的丰富数据档案。 《国际运动科学杂志》（International Journal of Exercise Science）2013 年的一项研究，研究了大学生铅球运动员，并考察了力量与铅球距离的关系。 总体由 28 名女大学生运动员组成。 运动员在赛季前的“1RM power clean”中举起的最大值（公斤）是衡量力量的指标。 距离（米）是运动员个人最佳成绩。</p>
<pre><code class="lang-py">shotput = Table.read_table(<span class="hljs-string">'shotput.csv'</span>)
shotput
</code></pre>
<table>
<thead>
<tr>
<th>Weight Lifted</th>
<th>Shot Put Distance</th>
</tr>
</thead>
<tbody>
<tr>
<td>37.5</td>
<td>6.4</td>
</tr>
<tr>
<td>51.5</td>
<td>10.2</td>
</tr>
<tr>
<td>61.3</td>
<td>12.4</td>
</tr>
<tr>
<td>61.3</td>
<td>13</td>
</tr>
<tr>
<td>63.6</td>
<td>13.2</td>
</tr>
<tr>
<td>66.1</td>
<td>13</td>
</tr>
<tr>
<td>70</td>
<td>12.7</td>
</tr>
<tr>
<td>92.7</td>
<td>13.9</td>
</tr>
<tr>
<td>90.5</td>
<td>15.5</td>
</tr>
<tr>
<td>90.5</td>
<td>15.8</td>
</tr>
</tbody>
</table>
<p>（省略了 18 行）</p>
<pre><code class="lang-py">shotput.scatter(<span class="hljs-string">'Weight Lifted'</span>)
</code></pre>
<p><img src="img/13-41.png" alt=""></img></p>
<p>这不是橄榄形的散点图。 事实上，它似乎有一点非线性成分。 但是，如果我们坚持用一条直线来做出预测，那么所有直线之中仍然有一条最好的直线。</p>
<p>我们为回归线的斜率和截距建立公式，它来源于橄榄形的散点图，并给出了下列值：</p>
<pre><code class="lang-py">slope(shotput, <span class="hljs-string">'Weight Lifted'</span>, <span class="hljs-string">'Shot Put Distance'</span>)
<span class="hljs-number">0.098343821597819972</span>
intercept(shotput, <span class="hljs-string">'Weight Lifted'</span>, <span class="hljs-string">'Shot Put Distance'</span>)
<span class="hljs-number">5.9596290983739522</span>
</code></pre>
<p>即使散点图不是橄榄形，使用这些公式还有意义吗？ 我们可以通过求出使 MSE 最小的斜率和截距来回答这个问题。</p>
<p>我们将定义函数<code>shotput_linear_mse</code>，以斜体和截距作为参数并返回相应的 MSE。 然后将<code>minimize</code>应用于<code>shotput_linear_mse</code>将返回最优斜率和截距。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shotput_linear_mse</span><span class="hljs-params">(any_slope, any_intercept)</span>:</span>
    x = shotput.column(<span class="hljs-string">'Weight Lifted'</span>)
    y = shotput.column(<span class="hljs-string">'Shot Put Distance'</span>)
    fitted = any_slope*x + any_intercept
    <span class="hljs-keyword">return</span> np.mean((y - fitted) ** <span class="hljs-number">2</span>)
minimize(shotput_linear_mse)
array([ <span class="hljs-number">0.09834382</span>,  <span class="hljs-number">5.95962911</span>])
</code></pre>
<p>这些值与我们使用我们的公式得到的值相同。 总结：</p>
<p>无论散点图的形状如何，都有一条独特的线，可以使估计的均方误差最小。 它被称为回归线，其斜率和截距由下式给出：</p>
<p><img src="img/tex-13-10.gif" alt=""></img></p>
<blockquote>
<p>译者注：也就是<code>cov(x, y)/var(x)</code>。</p>
</blockquote>
<p><img src="img/tex-13-11.gif" alt=""></img></p>
<pre><code class="lang-py">fitted = fit(shotput, <span class="hljs-string">'Weight Lifted'</span>, <span class="hljs-string">'Shot Put Distance'</span>)
shotput.with_column(<span class="hljs-string">'Best Straight Line'</span>, fitted).scatter(<span class="hljs-string">'Weight Lifted'</span>)
</code></pre>
<p><img src="img/13-42.png" alt=""></img></p>
<h3 id="非线性回归">非线性回归</h3>
<p>上面的图表强化了我们之前的观察，即散点图有点弯曲。 因此，最好拟合曲线而不是直线。 研究假设举起的重量与铅球距离之间是二次关系。 所以让我们使用二次函数来预测，看看我们能否找到最好的曲线。</p>
<p>我们必须找到所有二次函数中最好的二次函数，而不是所有直线中最好的直线。 最小二乘法允许我们这样做。</p>
<p>这种最小化的数学是复杂的，不容易仅仅通过检查散点图来发现。 但是数值最小化和线性预测一样简单！ 再次通过使用最小化我们可以得到最好的二次预测。 让我们看看这是如何工作的。</p>
<p>回想一下，二次函数的形式：</p>
<pre><code>f(x) = ax^2 + bx + c
</code></pre><p><code>a</code>、<code>b</code>和<code>c</code>是常数。</p>
<p>为了基于举起的重量找到最好的二次函数来预测距离，使用最小二乘法，我们首先编写一个函数，以三个常量为自变量的，用上面的二次函数计算拟合值，然后返回均方误差。</p>
<p>该函数被称为<code>shotput_quadratic_mse</code>。 请注意，定义与<code>lw_mse</code>的定义类似，不同的是拟合值基于二次函数而不是线性。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">shotput_quadratic_mse</span><span class="hljs-params">(a, b, c)</span>:</span>
    x = shotput.column(<span class="hljs-string">'Weight Lifted'</span>)
    y = shotput.column(<span class="hljs-string">'Shot Put Distance'</span>)
    fitted = a*(x**<span class="hljs-number">2</span>) + b*x + c
    <span class="hljs-keyword">return</span> np.mean((y - fitted) ** <span class="hljs-number">2</span>)
</code></pre>
<p>我们现在可以像之前那样使用<code>minimize</code>，并找到使 MSE 最小的常数。</p>
<pre><code class="lang-py">best = minimize(shotput_quadratic_mse)
best
array([ <span class="hljs-number">-1.04004838e-03</span>,   <span class="hljs-number">2.82708045e-01</span>,  <span class="hljs-number">-1.53182115e+00</span>])
</code></pre>
<p>我们预测，一个举起<code>x</code>公斤的运动员的铅球距离大概是<code>-0.00104x^2 + 0.2827x - 1.5318</code>米。 例如，如果运动员可以举起 100 公斤，预测的距离是 16.33 米。 在散点图上，在 100 公斤左右的垂直条形的中心附近。</p>
<pre><code class="lang-py">(<span class="hljs-number">-0.00104</span>)*(<span class="hljs-number">100</span>**<span class="hljs-number">2</span>) + <span class="hljs-number">0.2827</span>*<span class="hljs-number">100</span> - <span class="hljs-number">1.5318</span>
<span class="hljs-number">16.3382</span>
</code></pre>
<p>以下是所有<code>Weight Lifted</code>的预测。 你可以看到他们穿过散点图的中心，大致上接近。</p>
<pre><code class="lang-py">x = shotput.column(<span class="hljs-number">0</span>)
shotput_fit = best.item(<span class="hljs-number">0</span>)*(x**<span class="hljs-number">2</span>) + best.item(<span class="hljs-number">1</span>)*x + best.item(<span class="hljs-number">2</span>)
shotput.with_column(<span class="hljs-string">'Best Quadratic Curve'</span>, shotput_fit).scatter(<span class="hljs-number">0</span>)
</code></pre>
<p><img src="img/13-43.png" alt=""></img></p>
<h2 id="视觉诊断">视觉诊断</h2>
<p>假设数据科学家已经决定使用线性回归，基于预测变量估计响应变量的值。 为了了解这种估计方法的效果如何，数据科学家必须知道估计值距离实际值多远。 这些差异被称为残差。</p>
<p><img src="img/tex-13-12.gif" alt=""></img></p>
<p>残差就是剩下的东西 - 估计之后的剩余。</p>
<p>残差是回归线和点的垂直距离。 散点图中的每个点都有残差。 残差是<code>y</code>的观测值与<code>y</code>的拟合值之间的差值，所以对于点<code>(x, y)</code>：</p>
<p><img src="img/tex-13-13.gif" alt=""></img></p>
<p><code>residual</code>函数计算残差。 该计算假设我们已经定义的所有相关函数：<code>standard_units</code>，<code>correlation</code>，<code>slope</code>，<code>intercept</code>和<code>fit</code>。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">residual</span><span class="hljs-params">(table, x, y)</span>:</span>
    <span class="hljs-keyword">return</span> table.column(y) - fit(table, x, y)
</code></pre>
<p>继续使用高尔顿的数据的例子，基于双亲身高（预测变量）来估计成年子女身高（响应变量），让我们计算出拟合值和残差。</p>
<pre><code class="lang-py">heights = heights.with_columns(
        <span class="hljs-string">'Fitted Value'</span>, fit(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>),
        <span class="hljs-string">'Residual'</span>, residual(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)
    )
heights
</code></pre>
<table>
<thead>
<tr>
<th>MidParent</th>
<th>Child</th>
<th>Fitted Value</th>
<th>Residual</th>
</tr>
</thead>
<tbody>
<tr>
<td>75.43</td>
<td>73.2</td>
<td>70.7124</td>
<td>2.48763</td>
</tr>
<tr>
<td>75.43</td>
<td>69.2</td>
<td>70.7124</td>
<td>-1.51237</td>
</tr>
<tr>
<td>75.43</td>
<td>69</td>
<td>70.7124</td>
<td>-1.71237</td>
</tr>
<tr>
<td>75.43</td>
<td>69</td>
<td>70.7124</td>
<td>-1.71237</td>
</tr>
<tr>
<td>73.66</td>
<td>73.5</td>
<td>69.5842</td>
<td>3.91576</td>
</tr>
<tr>
<td>73.66</td>
<td>72.5</td>
<td>69.5842</td>
<td>2.91576</td>
</tr>
<tr>
<td>73.66</td>
<td>65.5</td>
<td>69.5842</td>
<td>-4.08424</td>
</tr>
<tr>
<td>73.66</td>
<td>65.5</td>
<td>69.5842</td>
<td>-4.08424</td>
</tr>
<tr>
<td>72.06</td>
<td>71</td>
<td>68.5645</td>
<td>2.43553</td>
</tr>
<tr>
<td>72.06</td>
<td>68</td>
<td>68.5645</td>
<td>-0.564467</td>
</tr>
</tbody>
</table>
<p>（省略了 924 行）</p>
<p>如果要处理的变量太多，以可视化开始总是很有帮助的。 函数<code>scatter_fit</code>绘制数据的散点图，以及回归线。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">scatter_fit</span><span class="hljs-params">(table, x, y)</span>:</span>
    table.scatter(x, y, s=<span class="hljs-number">15</span>)
    plots.plot(table.column(x), fit(table, x, y), lw=<span class="hljs-number">4</span>, color=<span class="hljs-string">'gold'</span>)
    plots.xlabel(x)
    plots.ylabel(y)
scatter_fit(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)
</code></pre>
<p><img src="img/13-44.png" alt=""></img></p>
<p>通过绘制残差和预测变量来绘制残差图。函数<code>residual_plot</code>就是这样做的。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">residual_plot</span><span class="hljs-params">(table, x, y)</span>:</span>
    x_array = table.column(x)
    t = Table().with_columns(
            x, x_array,
            <span class="hljs-string">'residuals'</span>, residual(table, x, y)
        )
    t.scatter(x, <span class="hljs-string">'residuals'</span>, color=<span class="hljs-string">'r'</span>)
    xlims = make_array(min(x_array), max(x_array))
    plots.plot(xlims, make_array(<span class="hljs-number">0</span>, <span class="hljs-number">0</span>), color=<span class="hljs-string">'darkblue'</span>, lw=<span class="hljs-number">4</span>)
    plots.title(<span class="hljs-string">'Residual Plot'</span>)
residual_plot(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)
</code></pre>
<p><img src="img/13-45.png" alt=""></img></p>
<p>双亲身高在横轴上，就像原始散点图中一样。 但是现在纵轴显示了残差。 请注意，该图看上去以<code>y=0</code>的横线为中心（以深蓝色显示）。 还要注意，绘图没有显示上升或下降的趋势。 我们稍后会观察到所有的回归都是如此。</p>
<h3 id="回归诊断">回归诊断</h3>
<p>残差图有助于我们直观评估线性回归分析的质量。 这种评估被称为诊断。 函数<code>regression_diagnostic_plots</code>绘制原始散点图以及残差图，以便于比较。</p>
<pre><code class="lang-py"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">regression_diagnostic_plots</span><span class="hljs-params">(table, x, y)</span>:</span>
    scatter_fit(table, x, y)
    residual_plot(table, x, y)
regression_diagnostic_plots(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)
</code></pre>
<p><img src="img/13-46.png" alt=""></img></p>
<p><img src="img/13-47.png" alt=""></img></p>
<p>这个残差图表明，线性回归是合理的估计方法。 注意残差关于<code>y=0</code>的横线上下对称分布，相当于原始散点图大致上下对称。 还要注意，绘图的垂直延伸，在子女身高最常见的值上相当均匀。 换句话说，除了一些离群点之外，绘图并不是一些地方窄。另一些地方宽。</p>
<p>换句话说，在预测变量的观察范围内，回归的准确性似乎是相同的。</p>
<p>良好回归的残差图不显示任何规律。 在预测变量的范围内，残差在<code>y=0</code>的直线处上下相同。</p>
<h3 id="检测非线性">检测非线性</h3>
<p>绘制数据的散点图，通常表明了两个变量之间的关系是否是非线性的。 然而，通常情况下，残差图中比原始散点图中更容易发现非线性。 这通常是因为这两个图的规模：残差图允许我们放大错误，从而更容易找出规律。</p>
<p><img src="img/13-48.png" alt=""></img></p>
<p>我们的数据是海牛的年龄和长度的数据集，这是一种海洋哺乳动物（维基共享资源图）。 数据在一个名为<code>dugong</code>的表中。 年龄以年为单位，长度以米为单位。 因为海牛通常不跟踪他们的生日，年龄是根据他们的牙齿状况等变量来估计的。</p>
<pre><code class="lang-py">dugong = Table.read_table(<span class="hljs-string">'http://www.statsci.org/data/oz/dugongs.txt'</span>)
dugong = dugong.move_to_start(<span class="hljs-string">'Length'</span>)
dugong
</code></pre>
<table>
<thead>
<tr>
<th>Length</th>
<th>Age</th>
</tr>
</thead>
<tbody>
<tr>
<td>1.8</td>
<td>1</td>
</tr>
<tr>
<td>1.85</td>
<td>1.5</td>
</tr>
<tr>
<td>1.87</td>
<td>1.5</td>
</tr>
<tr>
<td>1.77</td>
<td>1.5</td>
</tr>
<tr>
<td>2.02</td>
<td>2.5</td>
</tr>
<tr>
<td>2.27</td>
<td>4</td>
</tr>
<tr>
<td>2.15</td>
<td>5</td>
</tr>
<tr>
<td>2.26</td>
<td>5</td>
</tr>
<tr>
<td>2.35</td>
<td>7</td>
</tr>
<tr>
<td>2.47</td>
<td>8</td>
</tr>
</tbody>
</table>
<p>（省略了 17 行）</p>
<p>如果我们可以衡量海牛的长度，对于它的年龄我们可以说什么呢？ 让我们来看看我们的数据说了什么。 这是一个长度（预测变量）和年龄（响应变量）的回归。 这两个变量之间的相关性相当大，为 0.83。</p>
<pre><code class="lang-py">correlation(dugong, <span class="hljs-string">'Length'</span>, <span class="hljs-string">'Age'</span>)
<span class="hljs-number">0.82964745549057139</span>
</code></pre>
<p>尽管相关性仍然很高，绘图显示出曲线规律，在残差图中更加明显。</p>
<pre><code class="lang-py">regression_diagnostic_plots(dugong, <span class="hljs-string">'Length'</span>, <span class="hljs-string">'Age'</span>)
</code></pre>
<p><img src="img/13-49.png" alt=""></img></p>
<p><img src="img/13-50.png" alt=""></img></p>
<p>虽然你可以发现原始散点图中的非线性，但在残差图中更明显。</p>
<p>在长度的较低一端，残差几乎都是正的；然后他们几乎都是负的；然后在较高一端，残差再次为正。 换句话说，回归估计值过高，然后过低，然后过高。 这意味着使用曲线而不是直线来估计年龄会更好。</p>
<p>当残差图显示了规律时，变量之间可能存在非线性关系。</p>
<h3 id="检测异方差">检测异方差</h3>
<p>异方差这个词，那些准备拼写游戏的人肯定会感兴趣。 对于数据科学家来说，其兴趣在于它的意义，即“不均匀延伸”。</p>
<p>回想一下<code>hybrid</code>表，包含美国混合动力汽车的数据。这是燃油效率对加速度的回归。这个关联是负面的：加速度高的汽车往往效率较低。</p>
<pre><code class="lang-py">regression_diagnostic_plots(hybrid, <span class="hljs-string">'acceleration'</span>, <span class="hljs-string">'mpg'</span>)
</code></pre>
<p><img src="img/13-51.png" alt=""></img></p>
<p><img src="img/13-52.png" alt=""></img></p>
<p>注意残差图在加速度的较低一端变得发散。 换句话说，对于较低的加速度，误差的大小的变化比较高值更大。 残差图中比原始的散点图中更容易注意到不均匀的变化。</p>
<p>如果残差图显示<code>y=0</code>的横线处的不均匀变化，则在预测变量的范围内，回归的估计不是同等准确的。</p>
<h2 id="数值诊断">数值诊断</h2>
<p>除了可视化之外，我们还可以使用残差的数值属性来评估回归的质量。 我们不会在数学上证明这些属性。 相反，我们将通过计算来观察它们，看看它们告诉我们回归的什么东西。</p>
<p>下面列出的所有事实都适用于散点图的所有形状，无论它们是否是线性的。</p>
<h3 id="残差图不展示形状">残差图不展示形状</h3>
<p>对于每一个线性回归，无论是好还是坏，残差图都不展示任何趋势。 总的来说，它是平坦的。 换句话说，残差和预测变量是不相关的。</p>
<p>你可以在上面所有的残差图中看到它。 我们还可以计算每种情况下，预测变量和残差之间的相关性。</p>
<pre><code class="lang-py">correlation(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Residual'</span>)
<span class="hljs-number">-2.7196898076470642e-16</span>
</code></pre>
<p>这看起来不是零，但它是个很小的数字，除了由于计算的舍入误差之外，它就是零。 在这里也一样，取小数点后 10 位。 减号是因为上面的舍入。</p>
<pre><code class="lang-py">round(correlation(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Residual'</span>), <span class="hljs-number">10</span>)
<span class="hljs-number">-0.0</span>
dugong = dugong.with_columns(
       <span class="hljs-string">'Fitted Value'</span>, fit(dugong, <span class="hljs-string">'Length'</span>, <span class="hljs-string">'Age'</span>),
       <span class="hljs-string">'Residual'</span>, residual(dugong, <span class="hljs-string">'Length'</span>, <span class="hljs-string">'Age'</span>)
)
round(correlation(dugong, <span class="hljs-string">'Length'</span>, <span class="hljs-string">'Residual'</span>), <span class="hljs-number">10</span>)
<span class="hljs-number">0.0</span>
</code></pre>
<h3 id="残差的均值">残差的均值</h3>
<p>不管散点图的形状如何，剩余的均值都是 0。</p>
<p>这类似于这样一个事实，如果你选取任何数值列表并计算距离均值的偏差的列表，则偏差的均值为 0。</p>
<p>在上面的所有残差图中，你看到<code>y=0</code>的横线穿过图的中心。 这是这个事实的可视化。</p>
<p>作为一个数值示例，这里是高尔顿数据集中，基于双亲高度的子女高度的回归的残差均值。</p>
<pre><code class="lang-py">round(np.mean(heights.column(<span class="hljs-string">'Residual'</span>)), <span class="hljs-number">10</span>)
<span class="hljs-number">0.0</span>
</code></pre>
<p>海牛长度和年龄的回归的残差均值也是一样。 残差均值为 0，除了舍入误差。</p>
<pre><code class="lang-py">round(np.mean(dugong.column(<span class="hljs-string">'Residual'</span>)), <span class="hljs-number">10</span>)
<span class="hljs-number">0.0</span>
</code></pre>
<h3 id="残差的标准差">残差的标准差</h3>
<p>无论散点图的形状如何，残差的标准差是响应变量的标准差的一个比例。 比例是 <img src="img/tex-13-14.gif" alt=""></img>。</p>
<p><img src="img/tex-13-15.gif" alt=""></img></p>
<p>我们将很快看到，它如何衡量回归估计的准确性。 但首先，让我们通过例子来确认。</p>
<p>在子女身高和双亲身高的案例中，残差的标准差约为 3.39 英寸。</p>
<pre><code class="lang-py">np.std(heights.column(<span class="hljs-string">'Residual'</span>))
<span class="hljs-number">3.3880799163953426</span>
</code></pre>
<p>这和响应变量的标准差乘<code>sqrt(1 - r^2)</code>相同。</p>
<pre><code class="lang-py">r = correlation(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)
np.sqrt(<span class="hljs-number">1</span> - r**<span class="hljs-number">2</span>) * np.std(heights.column(<span class="hljs-string">'Child'</span>))
<span class="hljs-number">3.3880799163953421</span>
</code></pre>
<p>混合动力汽车的加速和里程的回归也是如此。 相关性<code>r</code>是负数（约 -0.5），但<code>r^2</code>是正数，所以<code>sqrt(1 - r^2)</code>是一个分数。</p>
<pre><code class="lang-py">r = correlation(hybrid, <span class="hljs-string">'acceleration'</span>, <span class="hljs-string">'mpg'</span>)
r
<span class="hljs-number">-0.5060703843771186</span>
hybrid = hybrid.with_columns(
     <span class="hljs-string">'fitted mpg'</span>, fit(hybrid, <span class="hljs-string">'acceleration'</span>, <span class="hljs-string">'mpg'</span>),
     <span class="hljs-string">'residual'</span>, residual(hybrid, <span class="hljs-string">'acceleration'</span>, <span class="hljs-string">'mpg'</span>)
)
np.std(hybrid.column(<span class="hljs-string">'residual'</span>)), np.sqrt(<span class="hljs-number">1</span> - r**<span class="hljs-number">2</span>)*np.std(hybrid.column(<span class="hljs-string">'mpg'</span>))
(<span class="hljs-number">9.4327368334302903</span>, <span class="hljs-number">9.4327368334302903</span>)
</code></pre>
<p>现在让我们看看，残差的标准差是如何衡量回归的好坏。请记住，残差的均值为 0。因此，残差的标准差越小，则残差越接近于 0。换句话说，如果残差的标准差小，那么回归中的总体误差就小。</p>
<p>极端情况是<code>r = 1</code>或<code>r = -1</code>。在这两种情况下，<code>sqrt(1 - r^2) = 0</code>。因此，残差的均值为 0，标准差为 0，因此残差都等于 0。回归线确实是完美的估计。我们在本章的前面看到，如果<code>r = ± 1</code>，散点图是一条完美的直线，与回归线相同，所以回归估计中确实没有错误。</p>
<p>但通常<code>r</code>不是极端的。如果<code>r</code>既不是<code>±1</code>也不是 0，那么<code>sqrt(1 - r^2)</code>是一个适当的分数，并且回归估计的误差大小，整体上大致在 0 和<code>y</code>的标准差之间。</p>
<p>最糟糕的情况是<code>r = 0</code>。那么<code>sqrt(1 - r^2)</code> = 1，残差的标准差等于<code>y</code>的标准差。这与观察结果一致，如果<code>r = 0</code>那么回归线就是<code>y</code>的均值上的一条横线。在这种情况下，回归的均方根误差是距离<code>y</code>的平均值的偏差的均方根，这是<code>y</code>的标准差。实际上，如果<code>r = 0</code>，那么这两个变量之间就没有线性关联，所以使用线性回归没有任何好处。</p>
<h3 id="另一种解释r的方式">另一种解释<code>r</code>的方式</h3>
<p>我们可以重写上面的结果，不管散点图的形状如何：</p>
<p><img src="img/tex-13-16.gif" alt=""></img></p>
<p>互补的结果是，无论散点图的形状如何，拟合值的标准差是观察值<code>y</code>的标准差的一个比例。比例是<code>|r|</code>。</p>
<p><img src="img/tex-13-17.gif" alt=""></img></p>
<p>要查看比例在哪里出现，请注意拟合值全部位于回归线上，而<code>y</code>的观测值是散点图中所有点的高度，并且更加可变。</p>
<pre><code class="lang-py">scatter_fit(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)
</code></pre>
<p><img src="img/13-53.png" alt=""></img></p>
<p>拟合值的范围在 64 到 71 之间，而所有子女的身高则变化很大，大约在 55 到 80 之间。</p>
<p>为了在数值上验证结果，我们只需要计算双方的一致性。</p>
<pre><code class="lang-py">correlation(heights, <span class="hljs-string">'MidParent'</span>, <span class="hljs-string">'Child'</span>)
<span class="hljs-number">0.32094989606395924</span>
</code></pre>
<p>这里是出生体重的拟合值的标准差与观察值的标准差的比值：</p>
<pre><code class="lang-py">np.std(heights.column(<span class="hljs-string">'Fitted Value'</span>))/np.std(heights.column(<span class="hljs-string">'Child'</span>))
<span class="hljs-number">0.32094989606395957</span>
</code></pre>
<p>这个比例等于<code>r</code>，证实了我们的结果。</p>
<p>绝对值出现在哪里？ 首先要注意的是，标准差不能是负数，标准差的比值也不行。 那么当<code>r</code>是负数时会发生什么呢？ 燃油效率和加速度的例子将向我们展示。</p>
<pre><code class="lang-py">correlation(hybrid, <span class="hljs-string">'acceleration'</span>, <span class="hljs-string">'mpg'</span>)
<span class="hljs-number">-0.5060703843771186</span>
np.std(hybrid.column(<span class="hljs-string">'fitted mpg'</span>))/np.std(hybrid.column(<span class="hljs-string">'mpg'</span>))
<span class="hljs-number">0.5060703843771186</span>
</code></pre>
<p>两个标准差的比值就是<code>|r|</code>。</p>
<p>解释这个结果的更标准的方法是，回想一下：</p>
<p><img src="img/tex-13-18.gif" alt=""></img></p>
<p>因此，对结果的两边取平方：</p>
<p><img src="img/tex-13-19.gif" alt=""></img></p>

                                
                                </section>
                            
                        </div>
                    </div>
                
            </div>

            
                
                <a href="12.html" class="navigation navigation-prev " aria-label="Previous page: 十二、为什么均值重要">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="14.html" class="navigation navigation-next " aria-label="Next page: 十四、回归的推断">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"十三、预测","level":"1.8.5.14","depth":3,"next":{"title":"十四、回归的推断","level":"1.8.5.15","depth":3,"path":"math/data8/14.md","ref":"math/data8/14.md","articles":[]},"previous":{"title":"十二、为什么均值重要","level":"1.8.5.13","depth":3,"path":"math/data8/12.md","ref":"math/data8/12.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["highlight","mathjax-pro","-search","-lunr","-sharing","-search-pro","expandable-chapters-small","splitter","back-to-top-button","github","code"],"pluginsConfig":{"github":{"url":"https://github.com/KittenCN"},"splitter":{},"code":{"copyButtons":true},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{"lang":{"eval_rst":"rst","toc":"text"}},"back-to-top-button":{},"mathjax-pro":{"forceSVG":false,"version":"2.7.7"},"expandable-chapters-small":{},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"math/data8/13.md","mtime":"2018-03-04T12:09:02.000Z","type":"markdown"},"gitbook":{"version":"6.0.2","time":"2025-04-25T11:51:46.251Z"},"basePath":"../..","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="../../gitbook/gitbook.js"></script>
    <script src="../../gitbook/theme.js"></script>
    
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-mathjax-pro/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-splitter/splitter.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="../../gitbook/gitbook-plugin-code/plugin.js"></script>
        
    
        
        <script src="../../gitbook/@honkit/honkit-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

