
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>2.1 监督学习 · CoderFAN 资料库</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 6.0.3">
        <meta name="author" content="Todd Lyu">
        
        
    
    <link rel="stylesheet" href="gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-back-to-top-button/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-code/plugin.css">
                
            
                
                <link rel="stylesheet" href="gitbook/gitbook-plugin-highlight/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="2.2.html" />
    
    
    <link rel="prev" href="1.html" />
    
    <!-- MathJax 配置：唯一且完整 -->
<script>
    window.MathJax = {
      tex: {
        inlineMath:  [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$','$$'], ['\\[','\\]']],
        processEscapes: true,
        processEnvironments: true,
        strict: "ignore",
        macros: { "\\E":"\\mathbb{E}", "\\Var":"\\operatorname{Var}" }
      },
    };
    </script>
    
    <!-- 核心脚本（defer不阻塞渲染） -->
    <script defer src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
    <!-- 放在 tex-chtml.js 之后 -->
    <script>
    (function () {
      function typeset() {
        if (window.MathJax && MathJax.typesetPromise) {
          MathJax.typesetPromise().catch(console.error);
        }
      }
    
      /* 第一次正文插入 */
      document.addEventListener('DOMContentLoaded', typeset);
    
      /*   关键：等待 gitbook.js 初始化成功   */
      function hookGitBook() {
        if (window.gitbook && gitbook.events) {
          gitbook.events.bind('page.change', typeset);   // 切章排版
        } else {
          /* gitbook.js 还没加载完 → 100 ms 后再试 */
          setTimeout(hookGitBook, 100);
        }
      }
      hookGitBook();   // 启动递归等待
    })();
    </script>
    
    

    </head>
    <body>
        
<div class="book honkit-cloak">
    <div class="book-summary">
        
            
            
                <nav role="navigation">
                <a href=".." class="btn"><b></b>&#128512;返回上层&#128512;</b></a>
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="./">
            
                <a href="./">
            
                    
                    写给人类的机器学习
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.1.1" data-path="READ_ME.html">
            
                <a href="READ_ME.html">
            
                    
                    写给人类的机器学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.2" data-path="1.html">
            
                <a href="1.html">
            
                    
                    一、为什么机器学习重要
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.1.3" data-path="2.1.html">
            
                <a href="2.1.html">
            
                    
                    2.1 监督学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.4" data-path="2.2.html">
            
                <a href="2.2.html">
            
                    
                    2.2 监督学习 II
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.5" data-path="2.3.html">
            
                <a href="2.3.html">
            
                    
                    2.3 监督学习 III
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.6" data-path="3.html">
            
                <a href="3.html">
            
                    
                    三、无监督学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.7" data-path="4.html">
            
                <a href="4.html">
            
                    
                    四、神经网络和深度学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.8" data-path="5.html">
            
                <a href="5.html">
            
                    
                    五、强化学习
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.1.9" data-path="6.html">
            
                <a href="6.html">
            
                    
                    六、最好的机器学习资源
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href="." >2.1 监督学习</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
                                <section class="normal markdown-section">
                                
                                <h1 id="21-监督学习">2.1 监督学习</h1>
<blockquote>
<p>原文：<a href="https://medium.com/machine-learning-for-humans/supervised-learning-740383a2feab" target="_blank">Machine_Learning_for_Humans, Part 2.1: Supervised Learning</a></p>
<p>作者：<a href="mailto:ml4humans@gmail.com" target="_blank">Vishal Maini</a></p>
<p>译者：<a href="https://github.com/wizardforcel" target="_blank">飞龙</a></p>
<p>协议：<a href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a></p>
<p>监督学习的两大任务：回归和分类。线性回归，损失函数和梯度下降。</p>
</blockquote>
<p>通过在数字广告上花费更多的钱，我们能挣多少钱？这个贷款的申请人是否能偿还贷款？股市明天会发生什么？</p>
<p>在监督学习的问题中，我们以一个数据集开始，它包含训练样本，每个样本带有关联的正确标签。例如，学习分类手写数字的时候，监督学习算法接受数千张手写体数字的图片，以及标签，它们包含每个图片表示的正确数字。算法会学习图像和关联的数值的关系。之后将学到的关系用于划分全新的图片（不带标签），机器从来没有见过它们。这就是你可以通过使用手机拍张照片，来存入支票的原因。</p>
<p>为了展示监督学习的工作原理，让我们看一个问题，根据某人完成的高等教育的年数，来预测年收入。更形式化来说，我们打算构建一个模型，它近似描述了高等教育年数<code>X</code>和对应年收入<code>Y</code>的关系<code>f</code>。</p>
<pre><code>Y = f(X) + ϵ
</code></pre><blockquote>
<p><code>X</code>（输入）为高等教育的年数
<code>Y</code>（输出）为年收入
<code>f</code>为描述<code>X</code>和<code>Y</code>关系的函数
<code>ϵ</code>（epsilon）为随机误差项（可正可负），均值为零</p>
<p>关于<code>ϵ</code>：</p>
<p><code>ϵ</code>表示模型的残余误差，它是你的算法的理论极限，由于你尝试解释的现象中存在固有噪声。例如，想象构建一个模型来预测抛硬币的结果。</p>
<p>此外，数学家 <a href="https://archive.is/o/VGPh3/https://en.wikipedia.org/wiki/Paul_Erd%C5%91s" target="_blank">Paul Erdős</a> 将孩子们称为<code>ϵ</code>，因为在微积分中（而不是统计学），<code>ϵ</code>代表任意小的正数值。很恰当吧？</p>
</blockquote>
<p>一种预测收入的方式，就是创建一个基于规则的严格模型，来表示收入和教育如何相关。例如，我估计出，高等教育每增加一年，年收入增加 $5000。</p>
<pre><code>income = ($5,000 * years_of_education) + baseline_income
</code></pre><blockquote>
<p>这个方式就是构建一个解的示例（而不是学习一个解，就像下面描述的线性回归方法那样）。</p>
</blockquote>
<p>通过包含一些规则，关于学位类型、工作年数、学校的层次，以及其它，你可以提出一个更复杂的模型。例如，“如果他们完成了学士或更高的学位，就将收入估计为 1.5 倍”。</p>
<p>但是这种类型的，明确的基于规则的规划，对于复杂数据不是很有效。想像一下，尝试设计一个图像分类器算法，它由<code>if-then</code>语句组成。这些语句描述了像素亮度的组合，来判断它是否是一只猫。</p>
<p>监督机器学习通过让计算机为你工作，来解决这个问题。通过识别数据中的规律，机器能够得到启发。这个和人类学习最大的差异是，机器学习运行在计算机硬件上，并且可以通过计算机科学和统计学的视角很好地理解，然而人类的模式识别发生在生物大脑中（不过完成了相同的目标）。</p>
<p>在监督学习中，机器试图从零开始 学习收入和教育之间的关系，通过使用带标签的训练数据来运行算法。习得的函数可以用于估计人们的收入，其中收入<code>Y</code>是未知的，只要我们将教育年数<code>X</code>作为输入。换句话说，我们可以将我们的模型用于不带标签的测试数据来估计<code>Y</code>。</p>
<p>监督学习的目标是，当获得<code>X</code>已知<code>Y</code>未知的新样本时，尽可能准确地预测<code>Y</code>。下面我们会探索多种最常见的方法。</p>
<h2 id="监督学习的两个任务：回归和分类">监督学习的两个任务：回归和分类</h2>
<blockquote>
<p>回归：预测连续数值。某个房子售价是多少？</p>
<p>分类：分配标签。某幅画是猫还是狗？</p>
</blockquote>
<p>这一节的剩余部分会关注回归。2.2 节中我们会深入分类方法。</p>
<h2 id="回归：预测连续值">回归：预测连续值</h2>
<p>回归预测连续的目标变量<code>Y</code>。它允许你估计一个值，例如房价或者人类寿命，基于输入数据<code>X</code>。</p>
<p>这里，目标变量的意思是我们所关心的，用于预测的位置变量。连续的意思是，在<code>Y</code>可以取的值中，不存在间隔（不连续）。另一方面，离散变量，只可以取有限个数的值。例如，孩子的数量是个连续变量。</p>
<p>收入的预测是个经典的回归问题。你的输入数据<code>X</code>包含所有数据集中的个体的相关信息，可以用于预测收入，例如教育年数、工作年数、职位、或者邮政编码。这些属性叫做特征，它们可以是数值（例如工作年数），或者分类（例如职位和研究领域）。</p>
<p>你可能想要尽可能多的，和这些特征相关的训练观测值，来定位输出<code>Y</code>，使你的模型可以学习<code>X</code>和<code>Y</code>之间的关系<code>f</code>。</p>
<p>数据分为训练集和测试集。训练集拥有标签，所以你的模型可以从这些带标签的样本中学习。测试集不带标签，也就是，你还不知道你尝试预测的值。你的模型可以推广到从未见过的情况，以便它在测试数据上表现良好，这个十分重要。</p>
<blockquote>
<p>回归</p>
<p><code>Y = f(X) + ϵ</code>，其中<code>X = (x1, x2 … xn)</code></p>
<p>训练：机器从带标签的训练数据习得<code>f</code></p>
<p>测试：机器从不带标签的测试数据预测<code>Y</code></p>
<p>要注意，<code>X</code>可以是个张量，它的维度可以是任意的。一维张量是向量（一行多列），二维张量是矩阵（多行多列）。你也可以拥有三、四、五甚至更高维的张量（例如三维张量拥有行、列和深度）。为了回顾这些术语，请参考<a href="https://www.deeplearningbook.org/contents/linear_algebra.html" target="_blank">线性代数回顾</a>的前几页。</p>
</blockquote>
<p>在我们的非常简单的二维示例中，它的形式是<code>csv</code>文件，其中每行包含一个人的教育水平和收入。使用更多特征来添加更多的列，你可以拥有更加复杂但是可能更加准确的模型。</p>
<p><img src="img/2-1.png" alt=""></img></p>
<h2 id="所以我们如何解决这些问题？">所以我们如何解决这些问题？</h2>
<p>我们如何构建模型，在现实世界中做出更准确、实用的预测？我们可以通过使用监督学习算法来实现。</p>
<p>现在让我们进行最有意思的部分：了解算法。我们会探索几种方式来实现回归和分类，并且展示机器学习概念中的关键。</p>
<h2 id="线性回归（普通最小二乘）">线性回归（普通最小二乘）</h2>
<blockquote>
<p>画一条直线。是的，这也算机器学习。</p>
</blockquote>
<p>首先，我们专注于使用线性回归解决收入预测问题，因为线性模型不是很适合图像识别任务（这是深度学习的领域，我们之后也会探索）。</p>
<p>我们拥有数据集<code>X</code>，以及对应的目标值<code>Y</code>。普通最小二乘（OLS）的目标是，习得一个线性模型，如果我们得到了一个未见过的<code>x</code>，我们可以用它来预测新的<code>y</code>，并且误差尽可能小。我们打算基于某个人的教育年数，猜测它的收入。</p>
<pre><code class="lang-py">X_train = [<span class="hljs-number">4</span>, <span class="hljs-number">5</span>, <span class="hljs-number">0</span>, <span class="hljs-number">2</span>, …, <span class="hljs-number">6</span>] <span class="hljs-comment"># 高等教育的年数</span>
Y_train = [<span class="hljs-number">80</span>, <span class="hljs-number">91.5</span>, <span class="hljs-number">42</span>, <span class="hljs-number">55</span>, …, <span class="hljs-number">100</span>] <span class="hljs-comment"># 对应的年收入，单位为千美元</span>
</code></pre>
<p><img src="img/2-2.png" alt=""></img></p>
<p>线性回归是个参数化方法，也就是说，它需要作出<code>X</code>和<code>Y</code>的函数形式的假设（我们之后会涉及非参数化方法的示例）。我们的模型是个函数，使用特定的<code>x</code>预测<code>ŷ</code>：</p>
<p><img src="img/2-3.png" alt=""></img></p>
<blockquote>
<p>这里，我们做出了一个明确的假设，<code>X</code>和<code>Y</code>是存在线性关系的。也就是说，对于每个<code>X</code>中的单位增长，<code>Y</code>的增长（或下降）不变。</p>
</blockquote>
<p><code>β0</code>是纵截距，<code>β1</code>是直线斜率，也就是教育每增加一年，收入增长（或者下降）多少。</p>
<p>我们的目标是，习得模型参数（这里是<code>β0</code>和<code>β1</code>），使模型预测中的误差最小。</p>
<p>为了寻找最佳的参数：</p>
<ol>
<li><p>定义一个成本函数，或者损失函数，它度量了我们的模型的预测有多么准确。</p>
</li>
<li><p>寻找使损失最小的参数，也就是，使我们的模型尽可能准确。</p>
</li>
</ol>
<p>以图形的方式，在二维中，它会产生一条最佳拟合直线。在三维中，我们可以画一个平面，所以高维中就是超平面。</p>
<blockquote>
<p>维度的注解：为了简便，我们的示例是二维的，但是你的模型通常拥有更多特征（<code>x</code>）和系数（<code>β</code>）。例如，添加更多相关变量，来提升模型预测的准确性。相同的原理可以推广到高维，虽然超过三维的东西很难可视化。</p>
</blockquote>
<p><img src="img/2-4.png" alt=""></img></p>
<p>在数学上，我们观察每个真实数据点（<code>y</code>）和我们的模型的预测（<code>ŷ</code>）之间的差。计算这些差的平方来避免负数，并惩罚较大的差，之后将它们相加并取平均。这度量了我们的数据有多么接近直线。</p>
<p><img src="img/2-5.png" alt=""></img></p>
<blockquote>
<p><code>n</code>为观察值的的数量。使用<code>2 * n</code>来代替<code>n</code>，在求导来使损失最小时，使我们的式子更加整洁，虽然一些统计学家认为这是这种亵渎。当你开始对这种东西有意见的时候，你就太偏执了。</p>
</blockquote>
<p>对于一个像这样的简单问题，我们可以使用微积分计算闭式解，来寻找最佳的<code>β</code>参数，它使我们的损失函数最小。但是随着成本函数的复杂性的增长，使用微积分寻找闭式解就不太可能了。这就推动了一种迭代方式，叫做梯度下降，它允许我们使复杂的损失函数最小。</p>
<h2 id="梯度下降：习得参数">梯度下降：习得参数</h2>
<blockquote>
<p>蒙住眼睛，向下走一步。当你无路可走只能向上的时候，你就到了底部。</p>
</blockquote>
<p>梯度下降会一遍一遍地出现，特别是在神经网络中。机器学习库，例如 scikit-learn 和 TensorFlow 会在背后的任何地方使用它，所以它值得了解细节。</p>
<p>梯度下降的目标是寻找我们模型的损失函数的最小值，通过在迭代中得到它的越来越好的近似值。</p>
<p>想象你自己蒙上眼睛穿过一个山谷。你的目标是寻找山谷的底部。你要怎么做呢？</p>
<p>一个可行的办法是，触摸你周围的地面，向地面下降最快的方向移动。走出一步，之后不断重复相同的过程，直到地面变成平的。之后你就知道了你到达了山谷的底部。如果你在所在位置向任何方向移动，你最终都会位于相同的高度，或者更高。</p>
<p>回到数学，地面变成了损失函数，山谷底部的高度变成了函数的最小值。</p>
<p>让我们看一看回归中的损失函数：</p>
<p><img src="img/2-6.png" alt=""></img></p>
<p>我们看到这个实际上是两个变量的函数：<code>β0</code>和<code>β1</code>。所有其余变量都是已确定的，因为<code>X</code>，<code>Y</code>和<code>n</code>都在训练过程中提供了。我们打算尝试使这个函数最小。</p>
<p><img src="img/2-7.png" alt=""></img></p>
<p>这个函数是<code>f(β0,β1)=z</code>。为了开始梯度下降，你需要对参数<code>β0</code>和<code>β1</code>做出一些猜测，它们使函数最小。</p>
<p>下面，你寻找损失函数对每个<code>β</code>参数的偏导数<code>[dz/dβ0, dz/dβ1]</code>。偏导数表示，如果你为<code>β0</code>或者<code>β1</code>增加一个很小的值，总损失增加或减少多少。</p>
<p>换一种方式。假设教育年数（<code>β0</code>）为零会增加模型的损失（也就是不准确度），这会将你的年收入的估计值增加多少？你需要向相反方向移动，以便你最终向下走并使损失最小。</p>
<p>与之类似，如果你增加“教育年数的每个增量会影响多少收入”的估计量（<code>β1</code>），这会将损失（<code>z</code>）增加多少？如果偏导数<code>dz/β1</code>是个复数，那么<code>β1</code>的增加是极好的，因为它会降低总损失。如果它是个正数，你需要降低<code>β1</code>。如果是零，不要修改<code>β1</code>，因为这表示你已经到达最优了。</p>
<p>持续做这件事，直到你到达了底部，也就是，算法收敛，损失到达最小。存在大量技巧和例外情况，它们超出了这一章的范围，但是通常来说，这就是你为你的参数化模型寻找最优参数的方式。</p>
<h2 id="过拟合">过拟合</h2>
<blockquote>
<p>过拟合：“Sherlock，你对刚才发生的事情的解释，太特定于这个环境了。”</p>
<p>正则化：“不要把事物过度复杂化，Sherlock。我会敲打你的每个额外的单词。”</p>
<p>超参数（<code>λ</code>）：这里就是我敲打你的每个额外的单词时的力量。</p>
</blockquote>
<p>机器学习的一个常见问题就是过拟合：习得一个函数，它完美解释了模型从中学习的训练数据，但是不能很好地推广到未见过的测试数据。过拟合在模型从训练数据过度学习时发生，它开始选取一些个性，它们不是现实世界中的典型规律。当你使你的模型变得复杂时，这就是个问题了。拟合不足是个相关的问题，其中你的模型不够复杂，不能捕获数据的隐含趋势。</p>
<blockquote>
<p>偏差和方差的权衡</p>
<p>偏差是误差总数，由使用简化的模型来近似真实世界的情况引入。</p>
<p>方差是你的模型的测试误差变化多少，基于训练数据的变化。它反映了模型对训练数据集的个性的敏感度。</p>
<p>随着模型复杂度的增长，它变得更加摆动（灵活），它的偏差下降（对解释训练数据有利），但是方差增加（也更难推广）。最终，为了得到良好的模型，你需要低偏差和低方差的模型。</p>
</blockquote>
<p><img src="img/2-8.png" alt=""></img></p>
<blockquote>
<p>来源：Coursera 的机器学习课程，由吴恩达讲授</p>
</blockquote>
<p>要记住，我们关心的唯一的事情就是，模型在测试数据上如何表现。你打算在标记邮件之前，预测哪个邮件会标记为垃圾，而不仅仅是构建一个模型，它可以以 100% 准确度，重新分类最开始用于构建自身的邮件。马后炮是 20/20，真正的问题是学到的经验是否在未来有所帮助。</p>
<p>右边的模型对于训练数据是零损失的，因为它完美拟合了每个数据点。但是这个经验不能推广。对于解释不在线上的数据点来说，这是个灾难性的任务。</p>
<p>两种避免过拟合的方法：</p>
<ol>
<li><p>使用更多训练数据。你拥有更多，通过从任意单一的训练样本大量学习，就更难过拟合数据。</p>
</li>
<li><p>使用正则化。在损失函数里添加一个惩罚，来构建一个模型，避免为任意一个特征分配过多的解释性权重，或者允许考虑过多特征。</p>
</li>
</ol>
<p><img src="img/2-9.png" alt=""></img></p>
<p>上面的和式的第一部分是正常的损失函数。第二部分就是正则项，为较大的<code>β</code>系数添加惩罚，它将过大的解释性权重给予任何特定的特征。同时使用这两个元素，成本函数现在平衡了两个优先级：解释训练数据，并防止解释过于特定。</p>
<p>损失函数中，正则项的<code>lambda</code>系数是个超参数：你的模型的通用设置，可以增加或者减少（也就是调整），以便改进表现。较高的<code>lambda</code>值会更严厉地惩罚较大的<code>β</code>参数，它们可能导致过拟合。为了决定<code>lambda</code>的最佳值，你可以使用叫做交叉验证的方法，它涉及在训练过程中，保留一部分训练数据，之后观察，模型对保留部分的解释有多好。我们会深入了解它。</p>
<h2 id="这就完成了">这就完成了</h2>
<p>这里是我们在这一节中涉及到的东西：</p>
<ul>
<li>监督机器学习如何让计算机，能够从带标签的训练数据中学习，而不需要显式编程。</li>
<li>监督学习的任务：回归和分类。</li>
<li>线性回归，简单而实用的参数化算法。</li>
<li>使用梯度下降习得参数。</li>
<li>过拟合和正则化</li>
</ul>
<p>下一节“2.2 节：监督机器学习 II”中，我们会讨论分类的两个基本方法：对数几率回归（LR）和支持向量机（SVM）。</p>
<h2 id="练习材料和扩展阅读">练习材料和扩展阅读</h2>
<h3 id="21a-线性回归">2.1a 线性回归</h3>
<p>对于线性回归的更彻底的讲授，阅读<a href="https://www-bcf.usc.edu/~gareth/ISL/index.html" target="_blank">《An Introduction to Statistical Learning》</a>的 1~3 章。这本书可以免费在线阅读，并且是用于使用配套练习理解机器学习概念的优秀资源。</p>
<p>对于更多练习：</p>
<ul>
<li>玩转<a href="https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html" target="_blank">波士顿房价数据集</a>。你可以使用带有漂亮 GUI 的软件，例如 Minitab 和 Excel，或者使用 Python 或者 R 用笨办法来完成它。</li>
<li>亲自尝试 Kaggle 挑战，例如房价预测，并在自己尝试之后，看看其他人如何解决问题。</li>
</ul>
<h3 id="21b-实现梯度下降">2.1b 实现梯度下降</h3>
<p>为了在 Python 中实际实现梯度下降，查阅<a href="https://spin.atomicobject.com/2014/06/24/gradient-descent-linear-regression/" target="_blank">这篇教程</a>。然后，<a href="https://eli.thegreenplace.net/2016/understanding-gradient-descent/" target="_blank">这里</a>是相同概念的更加数学化的严格描述。</p>
<p>在实战中，你很少需要从零开始实现梯度下降，但是理解它背后的工作原理，会让你更有效地使用它，并且在出现问题时理解其原因。</p>

                                
                                </section>
                            
                        </div>
                    </div>
                
            </div>

            
                
                <a href="1.html" class="navigation navigation-prev " aria-label="Previous page: 一、为什么机器学习重要">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="2.2.html" class="navigation navigation-next " aria-label="Next page: 2.2 监督学习 II">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"2.1 监督学习","level":"1.1.3","depth":2,"next":{"title":"2.2 监督学习 II","level":"1.1.4","depth":2,"path":"2.2.md","ref":"2.2.md","articles":[]},"previous":{"title":"一、为什么机器学习重要","level":"1.1.2","depth":2,"path":"1.md","ref":"1.md","articles":[]},"dir":"ltr"},"config":{"plugins":["-search","-livereload","-lunr","-fontsettings","highlight","expandable-chapters-small","back-to-top-button","github","code","theme-default"],"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"highlight":{"lang":{"eval_rst":"rst","toc":"text"}},"github":{"url":"https://github.com/KittenCN"},"expandable-chapters-small":{},"back-to-top-button":{},"code":{"copyButtons":true},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"Todd Lyu","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56},"embedFonts":false},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"CoderFAN 资料库","gitbook":"*"},"file":{"path":"2.1.md","mtime":"2025-04-20T03:04:06.718Z","type":"markdown"},"gitbook":{"version":"6.0.3","time":"2025-05-09T01:07:14.325Z"},"basePath":".","book":{"language":""}});
        });
    </script>
</div>

        
    <noscript>
        <style>
            .honkit-cloak {
                display: block !important;
            }
        </style>
    </noscript>
    <script>
        // Restore sidebar state as critical path for prevent layout shift
        function __init__getSidebarState(defaultValue){
            var baseKey = "";
            var key = baseKey + ":sidebar";
            try {
                var value = localStorage[key];
                if (value === undefined) {
                    return defaultValue;
                }
                var parsed = JSON.parse(value);
                return parsed == null ? defaultValue : parsed;
            } catch (e) {
                return defaultValue;
            }
        }
        function __init__restoreLastSidebarState() {
            var isMobile = window.matchMedia("(max-width: 600px)").matches;
            if (isMobile) {
                // Init last state if not mobile
                return;
            }
            var sidebarState = __init__getSidebarState(true);
            var book = document.querySelector(".book");
            // Show sidebar if it enabled
            if (sidebarState && book) {
                book.classList.add("without-animation", "with-summary");
            }
        }

        try {
            __init__restoreLastSidebarState();
        } finally {
            var book = document.querySelector(".book");
            book.classList.remove("honkit-cloak");
        }
    </script>
    <script src="gitbook/gitbook.js"></script>
    <script src="gitbook/theme.js"></script>
    
        
        <script src="gitbook/gitbook-plugin-expandable-chapters-small/expandable-chapters-small.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-back-to-top-button/plugin.js"></script>
        
    
        
        <script src="gitbook/gitbook-plugin-code/plugin.js"></script>
        
    

    </body>
</html>

